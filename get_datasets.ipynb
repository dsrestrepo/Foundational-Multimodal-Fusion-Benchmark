{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a83787a",
   "metadata": {},
   "source": [
    "### Setup Environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8615a01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.google_trends import get_interest_over_time\n",
    "from src.get_data import get_daquar_dataset, preprocess_daquar_dataset\n",
    "from src.get_data import get_cocoqa_dataset, process_cocoqa_data\n",
    "from src.get_data import download_fakeddit_files, create_stratified_subset_fakeddit, download_full_set_images, download_images_from_file\n",
    "from src.get_data import download_recipes5k_dataset, preprocess_recipes5k\n",
    "from src.get_data import get_brset, brset_preprocessing\n",
    "from src.get_data import preprocess_ham10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea4fe90",
   "metadata": {},
   "source": [
    "### Download Datasets:\n",
    "\n",
    "The Fusion Model has been evaluated in 4 different datasets:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2bd33c",
   "metadata": {},
   "source": [
    "## 1. DAQUAR\n",
    "\n",
    "* **[DAQUAR Dataset](https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/research/vision-and-language/visual-turing-challenge#c7057)**:\n",
    "\n",
    "DAQUAR (Dataset for Question Answering on Real-world images) dataset was created for the purpose of advancing research in visual question answering (VQA). It consists of indoor scene images, each accompanied by sets of questions related to the scene's content. The dataset serves as a benchmark for training and evaluating models in understanding images and answering questions about them.\n",
    "\n",
    "This dataset can be downloaded from the following [link](https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/research/vision-and-language/visual-turing-challenge#c7057). Or you can download the dataset using the function `get_daquar_dataset`.\n",
    "\n",
    "Once you have the dataset, use the function `preprocess_daquar_dataset` to proprocess the train and test set, and generate the `labes.csv` file.\n",
    "\n",
    "These functions will generate a dataset with the structure:\n",
    "\n",
    "* output_dir/\n",
    "    * labels.csv\n",
    "    * test.txt\n",
    "    * train.txt\n",
    "    * images/\n",
    "        * image1.png\n",
    "        * image2.png\n",
    "        * image3.png\n",
    "        \n",
    "        ...\n",
    "        \n",
    "        * imagen.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b2da588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images downloaded and uncompressed successfully.\n",
      "Labels downloaded successfully.\n",
      "Preprocessed data saved to datasets/daquar/labels.csv\n"
     ]
    }
   ],
   "source": [
    "output_dir = 'datasets/daquar/'\n",
    "get_daquar_dataset(output_dir)\n",
    "preprocess_daquar_dataset(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5850fa",
   "metadata": {},
   "source": [
    "## 2. COCO-QA\n",
    "\n",
    "* **[COCO-QA Dataset](https://www.cs.toronto.edu/~mren/research/imageqa/data/cocoqa/)**:\n",
    "\n",
    "The COCO-QA (COCO Question-Answering) dataset is designed for the task of visual question-answering. It is a subset of the COCO (Common Objects in Context) dataset, which is a large-scale dataset containing images with object annotations. The COCO-QA dataset extends the COCO dataset by including questions and answers associated with the images. Each image in the COCO-QA dataset is accompanied by a set of questions and corresponding answers.\n",
    "\n",
    "You can use the `get_cocoqa_dataset` Function to download the dataset.\n",
    "\n",
    "Example usage of the function:\n",
    "\n",
    "`get_cocoqa_dataset(output_dir=\"datasets/coco-qa/\")`\n",
    "\n",
    "Also run the function to preprocess the dataset:\n",
    "\n",
    "`process_cocoqa_data(output_dir=\"datasets/coco-qa/\")`\n",
    "\n",
    "After executing these functions, you will have the following structure in the \"datasets/coco-qa/\" directory:\n",
    "\n",
    "* datasets/coco-qa/\n",
    "    * labels.csv\n",
    "    * train/\n",
    "    * test/\n",
    "    * images/\n",
    "        * image1.png\n",
    "        * image2.png\n",
    "        * image3.png\n",
    "        \n",
    "        ...\n",
    "        \n",
    "        * imagen.png "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a259cb07",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84dde943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCO-QA dataset downloaded and uncompressed successfully.\n",
      "COCO images downloaded and uncompressed successfully.\n",
      "Train and test dataframes saved successfully.\n",
      "Combined dataframe saved successfully.\n",
      "Images removed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "output_dir = 'datasets/coco-qa/'\n",
    "get_cocoqa_dataset(output_dir)\n",
    "process_cocoqa_data(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54bf1d9",
   "metadata": {},
   "source": [
    "## 3. Fakeddit\n",
    "\n",
    "* **[Fakeddit Dataset](https://fakeddit.netlify.app/)**:\n",
    "\n",
    "Fakeddit is a large-scale multimodal dataset for fine-grained fake news detection. It consists of over 1 million samples from multiple categories of fake news, including satire, misinformation, and fabricated news. The dataset includes text, images, metadata, and comment data, making it a rich resource for developing and evaluating fake news detection models.\n",
    "\n",
    "You can use the se the function `download_fakeddit_files` to download the metadata, and the function `download_full_set_images`to get the full set of Images. \n",
    "\n",
    "Since the full set of images contains 1M images, we'll provide a function to generate a subset, to run the experiments with less resources. Use the function `create_stratified_subset_fakeddit`. This function will generate a `labels.csv` file with the subset.\n",
    "\n",
    "You can also use the `download_images_from_file` to download the images from an specific file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b134c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (uriginal): https://drive.google.com/uc?id=1cjY6HsHaSZuLVHywIxD5xQqng33J5S2b\n",
      "From (redirected): https://drive.google.com/uc?id=1cjY6HsHaSZuLVHywIxD5xQqng33J5S2b&confirm=t&uuid=25f70429-0d7f-4575-a219-133d8d39a23b\n",
      "To: /home/datascience/Data Fusion/datasets/fakeddit/Images.tar.bz2\n",
      "100%|██████████| 114G/114G [16:12<00:00, 117MB/s]    \n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "output_dir = 'datasets/fakeddit/'\n",
    "\n",
    "# Get Metadata:\n",
    "download_fakeddit_files(output_dir)\n",
    "\n",
    "# Get Images (Due to possible API changes, we recommend this method):\n",
    "download_full_set_images(output_dir)\n",
    "\n",
    "# Random subset:\n",
    "subset_size = 1  # 100% subset size\n",
    "# subset_size = 0.1  # 10% subset size\n",
    "create_stratified_subset_fakeddit(output_dir, subset_size)\n",
    "\n",
    "#download_images_from_file(output_dir, 'labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4215920",
   "metadata": {},
   "source": [
    "## 4. Recipes5k\n",
    "* **[Recipes5k Dataset](http://www.ub.edu/cvub/recipes5k/)**:\n",
    "\n",
    "The Recipes5k dataset comprises 4,826 recipes featuring images and corresponding ingredient lists, with 3,213 unique ingredients simplified from 1,014 by removing overly-descriptive particles, offering a diverse collection of alternative preparations for each of the 101 food types from Food101, meticulously balanced across training, validation, and test splits. The dataset addresses intra- and inter-class variability, extracted from Yummly with 50 recipes per food type.\n",
    "\n",
    "You can use the se the function `download_recipes5k_dataset` to download the dataset. Use the function `preprocess_recipes5k` to preprocess the dataset. These function will generate the following structure:\n",
    "\n",
    "* preprocess_recipes5k\n",
    "    * labels.csv\n",
    "    * Images/\n",
    "        * class_1/\n",
    "            * img_1\n",
    "            * img_2\n",
    "            ...\n",
    "        * class_2/\n",
    "            * img_1\n",
    "            * img_2\n",
    "            ...\n",
    "        ...\n",
    "        * class_n/\n",
    "            * img_1\n",
    "            * img_2\n",
    "            ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "436d42f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "# The function generates the directory 'Recipes5k' by default, so you don't have to specify that.\n",
    "output_dir = 'datasets/'\n",
    "download_recipes5k_dataset(output_dir)\n",
    "preprocess_recipes5k('datasets/Recipes5k/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c3490f",
   "metadata": {},
   "source": [
    "## 5. BRSET\n",
    "* **[BRSET Dataset](https://physionet.org/content/brazilian-ophthalmological/1.0.0/)**:\n",
    "\n",
    "The Brazilian Multilabel Ophthalmological Dataset (BRSET) stands as a pioneering initiative aimed at bridging the gap in ophthalmological datasets, particularly for under-represented populations in low and medium-income countries. This comprehensive dataset encompasses 16,266 images from 8,524 Brazilian patients, incorporating a wide array of data points including demographics, anatomical parameters of the macula, optic disc, and vessels, along with quality control metrics such as focus, illumination, image field, and artifacts.\n",
    "\n",
    "You can use the se the function `get_brset` to download the dataset. Use the function `brset_preprocessing` to preprocess the dataset. These function will generate the following structure:\n",
    "\n",
    "* brset/\n",
    "    * labels.csv\n",
    "    * Images/\n",
    "        * img_1\n",
    "        * img_2\n",
    "         \n",
    "         ...\n",
    "         \n",
    "        * img_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91d0d4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed dataset saved as labels.csv in datasets/brset\n"
     ]
    }
   ],
   "source": [
    "output_dir = 'datasets/brset'\n",
    "get_brset('datasets/brset', download=True)\n",
    "brset_preprocessing(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f206d9",
   "metadata": {},
   "source": [
    "# 6. HAM10000 dataset\n",
    "\n",
    "* [HAM10000 dataset](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/DBW86T)\n",
    "\n",
    "The MNIST: HAM10000 dataset is a large collection of dermatoscopic images from different populations, acquired and stored by the Department of Dermatology at the Medical University of Vienna, Austria. It consists of 10,015 dermatoscopic images which can serve as a training set for academic machine learning purposes in tasks like skin lesion analysis and classification, specifically focusing on the detection of melanoma.\n",
    "\n",
    "Unfortunately we cannot provide a function to download data automatically because users must sign the terms of use. Please use the [link](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/DBW86T) to download and uncompress the files and place them in the folder:\n",
    "* datasets/ham10000/HAM10000_images_part_1/\n",
    "    * fig1.jpg\n",
    "    * fig2.jpg\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    * fign.jpg\n",
    "* datasets/ham10000/HAM10000_images_part_2/\n",
    "    * fig1.jpg\n",
    "    * fig2.jpg\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    * fign.jpg\n",
    "* datasets/ham10000/HAM10000_metadata.csv\n",
    "\n",
    "Once you have the data placed, you can use the function preprocess_ham10000 to preprocess the dataset. Thi function will generate the prompt text of each patient, and save the data with the structure:\n",
    "\n",
    "* ham10000/\n",
    "    * labels.csv\n",
    "    * Images/\n",
    "        * img_1\n",
    "        * img_2\n",
    "         \n",
    "         ...\n",
    "         \n",
    "        * img_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bb7d254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>text</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8050</th>\n",
       "      <td>ISIC_0033319</td>\n",
       "      <td>nv</td>\n",
       "      <td>Patient diagnosed via histo. Age: 35 years. Se...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4898</th>\n",
       "      <td>ISIC_0030823</td>\n",
       "      <td>nv</td>\n",
       "      <td>Patient diagnosed via follow_up. Age: 40 years...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9695</th>\n",
       "      <td>ISIC_0028730</td>\n",
       "      <td>akiec</td>\n",
       "      <td>Patient diagnosed via histo. Age: 65 years. Se...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4090</th>\n",
       "      <td>ISIC_0027299</td>\n",
       "      <td>nv</td>\n",
       "      <td>Patient diagnosed via follow_up. Age: 40 years...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8625</th>\n",
       "      <td>ISIC_0032444</td>\n",
       "      <td>nv</td>\n",
       "      <td>Patient diagnosed via histo. Age: 65 years. Se...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7597</th>\n",
       "      <td>ISIC_0034116</td>\n",
       "      <td>nv</td>\n",
       "      <td>Patient diagnosed via histo. Age: 35 years. Se...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2586</th>\n",
       "      <td>ISIC_0026453</td>\n",
       "      <td>bcc</td>\n",
       "      <td>Patient diagnosed via histo. Age: 55 years. Se...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2169</th>\n",
       "      <td>ISIC_0029885</td>\n",
       "      <td>mel</td>\n",
       "      <td>Patient diagnosed via histo. Age: 35 years. Se...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1815</th>\n",
       "      <td>ISIC_0033226</td>\n",
       "      <td>mel</td>\n",
       "      <td>Patient diagnosed via histo. Age: 65 years. Se...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9600</th>\n",
       "      <td>ISIC_0033065</td>\n",
       "      <td>nv</td>\n",
       "      <td>Patient diagnosed via consensus. Age: No data ...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10015 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          image_id     dx                                               text  \\\n",
       "8050  ISIC_0033319     nv  Patient diagnosed via histo. Age: 35 years. Se...   \n",
       "4898  ISIC_0030823     nv  Patient diagnosed via follow_up. Age: 40 years...   \n",
       "9695  ISIC_0028730  akiec  Patient diagnosed via histo. Age: 65 years. Se...   \n",
       "4090  ISIC_0027299     nv  Patient diagnosed via follow_up. Age: 40 years...   \n",
       "8625  ISIC_0032444     nv  Patient diagnosed via histo. Age: 65 years. Se...   \n",
       "...            ...    ...                                                ...   \n",
       "7597  ISIC_0034116     nv  Patient diagnosed via histo. Age: 35 years. Se...   \n",
       "2586  ISIC_0026453    bcc  Patient diagnosed via histo. Age: 55 years. Se...   \n",
       "2169  ISIC_0029885    mel  Patient diagnosed via histo. Age: 35 years. Se...   \n",
       "1815  ISIC_0033226    mel  Patient diagnosed via histo. Age: 65 years. Se...   \n",
       "9600  ISIC_0033065     nv  Patient diagnosed via consensus. Age: No data ...   \n",
       "\n",
       "      split  \n",
       "8050  train  \n",
       "4898  train  \n",
       "9695  train  \n",
       "4090  train  \n",
       "8625  train  \n",
       "...     ...  \n",
       "7597   test  \n",
       "2586   test  \n",
       "2169   test  \n",
       "1815   test  \n",
       "9600   test  \n",
       "\n",
       "[10015 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'datasets/ham10000/'\n",
    "preprocess_ham10000(path, dir1='HAM10000_images_part_1', dir2='HAM10000_images_part_2', labels='HAM10000_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2eb42eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_fusion_v0_0_1]",
   "language": "python",
   "name": "conda-env-data_fusion_v0_0_1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
