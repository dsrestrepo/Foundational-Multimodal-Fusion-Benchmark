{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a83787a",
   "metadata": {},
   "source": [
    "### Setup Environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8615a01e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src.google_trends import get_interest_over_time\n",
    "from src.get_data import get_daquar_dataset, preprocess_daquar_dataset\n",
    "from src.get_data import get_cocoqa_dataset, process_cocoqa_data\n",
    "from src.get_data import download_fakeddit_files, create_stratified_subset_fakeddit, download_full_set_images, download_images_from_file\n",
    "from src.get_data import download_recipes5k_dataset, preprocess_recipes5k\n",
    "from src.get_data import get_brset, brset_preprocessing\n",
    "from src.get_data import preprocess_ham10000\n",
    "from src.get_data import get_satellitedata, satellitedata_preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea4fe90",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Download Datasets:\n",
    "\n",
    "The Fusion Model has been evaluated in 4 different datasets:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2bd33c",
   "metadata": {},
   "source": [
    "## 1. DAQUAR\n",
    "\n",
    "* **[DAQUAR Dataset](https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/research/vision-and-language/visual-turing-challenge#c7057)**:\n",
    "\n",
    "DAQUAR (Dataset for Question Answering on Real-world images) dataset was created for the purpose of advancing research in visual question answering (VQA). It consists of indoor scene images, each accompanied by sets of questions related to the scene's content. The dataset serves as a benchmark for training and evaluating models in understanding images and answering questions about them.\n",
    "\n",
    "This dataset can be downloaded from the following [link](https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/research/vision-and-language/visual-turing-challenge#c7057). Or you can download the dataset using the function `get_daquar_dataset`.\n",
    "\n",
    "Once you have the dataset, use the function `preprocess_daquar_dataset` to proprocess the train and test set, and generate the `labes.csv` file.\n",
    "\n",
    "These functions will generate a dataset with the structure:\n",
    "\n",
    "* output_dir/\n",
    "    * labels.csv\n",
    "    * test.txt\n",
    "    * train.txt\n",
    "    * images/\n",
    "        * image1.png\n",
    "        * image2.png\n",
    "        * image3.png\n",
    "        \n",
    "        ...\n",
    "        \n",
    "        * imagen.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2da588",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'datasets/daquar/'\n",
    "get_daquar_dataset(output_dir)\n",
    "preprocess_daquar_dataset(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5850fa",
   "metadata": {},
   "source": [
    "## 2. COCO-QA\n",
    "\n",
    "* **[COCO-QA Dataset](https://www.cs.toronto.edu/~mren/research/imageqa/data/cocoqa/)**:\n",
    "\n",
    "The COCO-QA (COCO Question-Answering) dataset is designed for the task of visual question-answering. It is a subset of the COCO (Common Objects in Context) dataset, which is a large-scale dataset containing images with object annotations. The COCO-QA dataset extends the COCO dataset by including questions and answers associated with the images. Each image in the COCO-QA dataset is accompanied by a set of questions and corresponding answers.\n",
    "\n",
    "You can use the `get_cocoqa_dataset` Function to download the dataset.\n",
    "\n",
    "Example usage of the function:\n",
    "\n",
    "`get_cocoqa_dataset(output_dir=\"datasets/coco-qa/\")`\n",
    "\n",
    "Also run the function to preprocess the dataset:\n",
    "\n",
    "`process_cocoqa_data(output_dir=\"datasets/coco-qa/\")`\n",
    "\n",
    "After executing these functions, you will have the following structure in the \"datasets/coco-qa/\" directory:\n",
    "\n",
    "* datasets/coco-qa/\n",
    "    * labels.csv\n",
    "    * train/\n",
    "    * test/\n",
    "    * images/\n",
    "        * image1.png\n",
    "        * image2.png\n",
    "        * image3.png\n",
    "        \n",
    "        ...\n",
    "        \n",
    "        * imagen.png "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a259cb07",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dde943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "output_dir = 'datasets/coco-qa/'\n",
    "get_cocoqa_dataset(output_dir)\n",
    "process_cocoqa_data(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54bf1d9",
   "metadata": {},
   "source": [
    "## 3. Fakeddit\n",
    "\n",
    "* **[Fakeddit Dataset](https://fakeddit.netlify.app/)**:\n",
    "\n",
    "Fakeddit is a large-scale multimodal dataset for fine-grained fake news detection. It consists of over 1 million samples from multiple categories of fake news, including satire, misinformation, and fabricated news. The dataset includes text, images, metadata, and comment data, making it a rich resource for developing and evaluating fake news detection models.\n",
    "\n",
    "You can use the se the function `download_fakeddit_files` to download the metadata, and the function `download_full_set_images`to get the full set of Images. \n",
    "\n",
    "Since the full set of images contains 1M images, we'll provide a function to generate a subset, to run the experiments with less resources. Use the function `create_stratified_subset_fakeddit`. This function will generate a `labels.csv` file with the subset.\n",
    "\n",
    "You can also use the `download_images_from_file` to download the images from an specific file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b134c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "output_dir = 'datasets/fakeddit/'\n",
    "\n",
    "# Get Metadata:\n",
    "download_fakeddit_files(output_dir)\n",
    "\n",
    "# Get Images (Due to possible API changes, we recommend this method):\n",
    "download_full_set_images(output_dir)\n",
    "\n",
    "# Random subset:\n",
    "subset_size = 1  # 100% subset size\n",
    "# subset_size = 0.1  # 10% subset size\n",
    "create_stratified_subset_fakeddit(output_dir, subset_size)\n",
    "\n",
    "#download_images_from_file(output_dir, 'labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4215920",
   "metadata": {},
   "source": [
    "## 4. Recipes5k\n",
    "* **[Recipes5k Dataset](http://www.ub.edu/cvub/recipes5k/)**:\n",
    "\n",
    "The Recipes5k dataset comprises 4,826 recipes featuring images and corresponding ingredient lists, with 3,213 unique ingredients simplified from 1,014 by removing overly-descriptive particles, offering a diverse collection of alternative preparations for each of the 101 food types from Food101, meticulously balanced across training, validation, and test splits. The dataset addresses intra- and inter-class variability, extracted from Yummly with 50 recipes per food type.\n",
    "\n",
    "You can use the se the function `download_recipes5k_dataset` to download the dataset. Use the function `preprocess_recipes5k` to preprocess the dataset. These function will generate the following structure:\n",
    "\n",
    "* preprocess_recipes5k\n",
    "    * labels.csv\n",
    "    * Images/\n",
    "        * class_1/\n",
    "            * img_1\n",
    "            * img_2\n",
    "            ...\n",
    "        * class_2/\n",
    "            * img_1\n",
    "            * img_2\n",
    "            ...\n",
    "        ...\n",
    "        * class_n/\n",
    "            * img_1\n",
    "            * img_2\n",
    "            ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436d42f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "# The function generates the directory 'Recipes5k' by default, so you don't have to specify that.\n",
    "output_dir = 'datasets/'\n",
    "download_recipes5k_dataset(output_dir)\n",
    "preprocess_recipes5k('datasets/Recipes5k/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c3490f",
   "metadata": {},
   "source": [
    "## 5. BRSET\n",
    "* **[BRSET Dataset](https://physionet.org/content/brazilian-ophthalmological/1.0.0/)**:\n",
    "\n",
    "The Brazilian Multilabel Ophthalmological Dataset (BRSET) stands as a pioneering initiative aimed at bridging the gap in ophthalmological datasets, particularly for under-represented populations in low and medium-income countries. This comprehensive dataset encompasses 16,266 images from 8,524 Brazilian patients, incorporating a wide array of data points including demographics, anatomical parameters of the macula, optic disc, and vessels, along with quality control metrics such as focus, illumination, image field, and artifacts.\n",
    "\n",
    "You can use the se the function `get_brset` to download the dataset. Use the function `brset_preprocessing` to preprocess the dataset. These function will generate the following structure:\n",
    "\n",
    "* brset/\n",
    "    * labels.csv\n",
    "    * Images/\n",
    "        * img_1\n",
    "        * img_2\n",
    "         \n",
    "         ...\n",
    "         \n",
    "        * img_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d0d4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'datasets/brset'\n",
    "get_brset('datasets/brset', download=True)\n",
    "brset_preprocessing(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f206d9",
   "metadata": {},
   "source": [
    "# 6. HAM10000 dataset\n",
    "\n",
    "* [HAM10000 dataset](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/DBW86T)\n",
    "\n",
    "The MNIST: HAM10000 dataset is a large collection of dermatoscopic images from different populations, acquired and stored by the Department of Dermatology at the Medical University of Vienna, Austria. It consists of 10,015 dermatoscopic images which can serve as a training set for academic machine learning purposes in tasks like skin lesion analysis and classification, specifically focusing on the detection of melanoma.\n",
    "\n",
    "Unfortunately we cannot provide a function to download data automatically because users must sign the terms of use. Please use the [link](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/DBW86T) to download and uncompress the files and place them in the folder:\n",
    "* datasets/ham10000/HAM10000_images_part_1/\n",
    "    * fig1.jpg\n",
    "    * fig2.jpg\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    * fign.jpg\n",
    "* datasets/ham10000/HAM10000_images_part_2/\n",
    "    * fig1.jpg\n",
    "    * fig2.jpg\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    * fign.jpg\n",
    "* datasets/ham10000/HAM10000_metadata.csv\n",
    "\n",
    "Once you have the data placed, you can use the function preprocess_ham10000 to preprocess the dataset. Thi function will generate the prompt text of each patient, and save the data with the structure:\n",
    "\n",
    "* ham10000/\n",
    "    * labels.csv\n",
    "    * Images/\n",
    "        * img_1\n",
    "        * img_2\n",
    "         \n",
    "         ...\n",
    "         \n",
    "        * img_n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701b70d9-d29b-44d6-8059-8500922e0420",
   "metadata": {},
   "source": [
    "## 7. Colombian Multimodal Satellite dataset\n",
    "* **[A Multi-Modal Satellite Imagery Dataset for Public Health Analysis in Colombia](https://physionet.org/content/multimodal-satellite-data/1.0.0/)**:\n",
    "\n",
    "The Multi-Modal Satellite Imagery Dataset in Colombia integrates economic, demographic, meteorological, and epidemiological data. It comprises 12,636 high-quality satellite images from 81 municipalities between 2016 and 2018, with minimal cloud cover. Its applications include deforestation monitoring, education indices forecasting, water quality assessment, extreme climatic event tracking, epidemic illness addressing, and precision agriculture optimization. We'll use it shortly.\n",
    "\n",
    "You can use the se the function `get_satellitedata` to download the dataset. Use the function `satellitedata_preprocessing` to preprocess the dataset. These function will generate the following structure:\n",
    "\n",
    "* satellitedata/\n",
    "    * labels.csv\n",
    "    * Images/\n",
    "        * N_DATE_1\n",
    "        * N_DATE_2\n",
    "         \n",
    "         ...\n",
    "         \n",
    "        * img_N_DATE_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb7d254",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dir = 'datasets/satellitedata'\n",
    "get_satellitedata('datasets/satellitedata', download=False)\n",
    "\n",
    "num_classes = 3\n",
    "\n",
    "df = satellitedata_preprocessing(output_dir, num_classes = num_classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retfound",
   "language": "python",
   "name": "retfound"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
