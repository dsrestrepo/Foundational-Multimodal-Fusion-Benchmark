{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55978b31",
   "metadata": {},
   "source": [
    "### Setup Environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3495ce91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from src.classifiers import preprocess_data, process_labels,split_data\n",
    "\n",
    "from src.classifiers import VQADataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.classifiers import train_early_fusion, train_late_fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3864c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'Embeddings/fakeddit_subset/'\n",
    "COLUMN = 'embeddings'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db46b46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_path, images_path = os.listdir(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184bc3c6",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9474bd2b",
   "metadata": {},
   "source": [
    "### Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a91fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pd.read_csv(os.path.join(PATH, text_path))\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab03b64",
   "metadata": {},
   "source": [
    "### Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3509ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = pd.read_csv(os.path.join(PATH, images_path))\n",
    "images.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf2d04a",
   "metadata": {},
   "source": [
    "### Merge and preprocess the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d425bb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocess_data(text, images, \"id\", \"ImageName\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00567789",
   "metadata": {},
   "source": [
    "## Data Perparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05a39bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "train_df, test_df = split_data(df)\n",
    "\n",
    "# Select features and labels vectors\n",
    "text_columns = [column for column in df.columns if 'text' in column] #[f'text_{i}']\n",
    "image_columns = [column for column in df.columns if 'image' in column] #[f'image_{i}']\n",
    "label_columns = '2_way_label'\n",
    "\n",
    "\n",
    "# Process and one-hot encode labels for training set\n",
    "train_labels, mlb, train_columns = process_labels(train_df, col=label_columns)\n",
    "test_labels = process_labels(test_df, col=label_columns, train_columns=train_columns)\n",
    "\n",
    "\n",
    "train_dataset = VQADataset(train_df, text_columns, image_columns, label_columns, mlb, train_columns)\n",
    "test_dataset = VQADataset(test_df, text_columns, image_columns, label_columns, mlb, train_columns)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4e2f1e",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da402d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input_size = len(text_columns)\n",
    "image_input_size = len(image_columns)\n",
    "output_size = len(mlb.classes_)\n",
    "multilabel = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d42f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train early fusion model\n",
    "print(\"Training Early Fusion Model:\")\n",
    "train_early_fusion(train_loader, test_loader, text_input_size, image_input_size, output_size, num_epochs=8, multilabel=multilabel, report=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1163fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train late fusion model\n",
    "print(\"Training Late Fusion Model:\")\n",
    "train_late_fusion(train_loader, test_loader, text_input_size, image_input_size, output_size, num_epochs=8, multilabel=multilabel, report=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0446281",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:retina_embeddings_v0_0_1]",
   "language": "python",
   "name": "conda-env-retina_embeddings_v0_0_1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
