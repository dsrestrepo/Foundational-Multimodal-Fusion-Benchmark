{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb95de2c",
   "metadata": {},
   "source": [
    "### Setup Environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4079177",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/datascience/conda/data_fusion_v0_0_1/lib/python3.8/site-packages/huggingface_hub/utils/_runtime.py:184: UserWarning: Pydantic is installed but cannot be imported. Please check your installation. `huggingface_hub` will default to not using Pydantic. Error message: '{e}'\n",
      "  warnings.warn(\n",
      "2024-02-08 18:56:34.576997: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-08 18:56:34.614132: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-08 18:56:35.430472: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from src.vlm_models import CLIP, BLIP2, LLAVA\n",
    "from src.classifiers_base import preprocess_df\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318f4bac",
   "metadata": {},
   "source": [
    "## Embeddings Generation\n",
    "\n",
    "* **Dataframe:** Pandas dataframe with image path and text\n",
    "\n",
    "* **Image Column:** Column with the path to the images\n",
    "\n",
    "* **Text Column:** Column with text data\n",
    "\n",
    "* **Batch Size:** Integer with the size of the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d57ffcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = 'blip2'\n",
    "#model_name = 'llava'\n",
    "model_name = 'clip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57b12b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Instance of CLIP model\n"
     ]
    }
   ],
   "source": [
    "if model_name.lower() == 'clip':\n",
    "    print('Creating Instance of CLIP model')\n",
    "    model = CLIP()\n",
    "elif model_name.lower() == 'blip2':\n",
    "    print('Creating Instance of BLIP 2 model')\n",
    "    model = BLIP2()\n",
    "elif model_name.lower() == 'llava':\n",
    "    print('Creating Instance of LLAVA model')\n",
    "    model = LLAVA()\n",
    "else:\n",
    "    raise NotImplementedError('The model should be clip, blip2 or llava')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c25fd50",
   "metadata": {},
   "source": [
    "## 1. DAQUAR\n",
    "\n",
    "* **[DAQUAR Dataset](https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/research/vision-and-language/visual-turing-challenge#c7057)**:\n",
    "\n",
    "DAQUAR (Dataset for Question Answering on Real-world images) dataset was created for the purpose of advancing research in visual question answering (VQA). It consists of indoor scene images, each accompanied by sets of questions related to the scene's content. The dataset serves as a benchmark for training and evaluating models in understanding images and answering questions about them.\n",
    "\n",
    "We'll use the function `get_embeddings_df` to generate the embeddings in `datasets/daquar/images` and store the embeddings in `Embeddings/daquar/Embeddings_Backbone.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20b5895",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12468/12468 [00:01<00:00, 9739.57it/s] \n",
      "100%|██████████| 12468/12468 [00:04<00:00, 2774.97it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26e93c1557c64ce4be98f526a91b3b19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing batches:   0%|          | 0/520 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "dataset = 'daquar'\n",
    "image_col = 'image_id'\n",
    "text_col = 'question'\n",
    "output_dir = f'Embeddings_vlm/{dataset}/'\n",
    "output_file = f'embeddings_{model_name}.csv'\n",
    "\n",
    "dataset_path = f'datasets/{dataset}/'\n",
    "images_dir = 'images/'\n",
    "labels = 'labels.csv'\n",
    "\n",
    "images_path = os.path.join(dataset_path, images_dir)\n",
    "labels_path = os.path.join(dataset_path, labels)\n",
    "\n",
    "df = preprocess_df(df=pd.read_csv(labels_path), image_columns=image_col, images_path=images_path)\n",
    "\n",
    "model.get_embeddings(dataframe=df, batch_size=batch_size, image_col_name=image_col, text_col_name=text_col, output_dir=output_dir, output_file=output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee90cbf",
   "metadata": {},
   "source": [
    "## 2. COCO-QA\n",
    "\n",
    "* **[COCO-QA Dataset](https://www.cs.toronto.edu/~mren/research/imageqa/data/cocoqa/)**:\n",
    "\n",
    "The COCO-QA (COCO Question-Answering) dataset is designed for the task of visual question-answering. It is a subset of the COCO (Common Objects in Context) dataset, which is a large-scale dataset containing images with object annotations. The COCO-QA dataset extends the COCO dataset by including questions and answers associated with the images. Each image in the COCO-QA dataset is accompanied by a set of questions and corresponding answers.\n",
    "\n",
    "We'll use the function `get_embeddings_df` to generate the embeddings in `datasets/coco-qa/images` and store the embeddings in `Embeddings/coco-qa/Embeddings_Backbone.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c23caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 24\n",
    "dataset = 'coco-qa'\n",
    "image_col = 'image_id'\n",
    "text_col = 'questions'\n",
    "output_dir = f'Embeddings_vlm/{dataset}'\n",
    "output_file = 'embeddings_clip.csv'\n",
    "\n",
    "dataset_path = f'datasets/{dataset}/'\n",
    "images_dir = 'images/'\n",
    "labels = 'labels.csv'\n",
    "\n",
    "images_path = os.path.join(dataset_path, images_dir)\n",
    "labels_path = os.path.join(dataset_path, labels)\n",
    "\n",
    "df = preprocess_df(df=pd.read_csv(labels_path), image_columns=image_col, images_path=images_path)\n",
    "\n",
    "model.get_embeddings(dataframe=df, batch_size=batch_size, image_col_name=image_col, text_col_name=text_col, output_dir=output_dir, output_file=output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6a4e33",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95c2431",
   "metadata": {},
   "source": [
    "## 2. Fakeddit\n",
    "\n",
    "* **[Fakeddit Dataset](https://fakeddit.netlify.app/)**:\n",
    "\n",
    "Fakeddit is a large-scale multimodal dataset for fine-grained fake news detection. It consists of over 1 million samples from multiple categories of fake news, including satire, misinformation, and fabricated news. The dataset includes text, images, metadata, and comment data, making it a rich resource for developing and evaluating fake news detection models.\n",
    "\n",
    "We'll use the function `get_embeddings_df` to generate the embeddings in `datasets/fakeddit/images` and store the embeddings in `Embeddings/fakeddit/Embeddings_Backbone.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d823bf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 24\n",
    "dataset = 'fakeddit'\n",
    "image_col = 'id'\n",
    "text_col = 'title'\n",
    "output_dir = f'Embeddings_vlm/{dataset}'\n",
    "output_file = 'embeddings_clip.csv'\n",
    "\n",
    "dataset_path = f'datasets/{dataset}/'\n",
    "images_dir = 'images/'\n",
    "labels = 'labels_subset.csv'\n",
    "\n",
    "images_path = os.path.join(dataset_path, images_dir)\n",
    "labels_path = os.path.join(dataset_path, labels)\n",
    "\n",
    "df = preprocess_df(df=pd.read_csv(labels_path), image_columns=image_col, images_path=images_path)\n",
    "\n",
    "model.get_embeddings(dataframe=df, batch_size=batch_size, image_col_name=image_col, text_col_name=text_col, output_dir=output_dir, output_file=output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1419ef55",
   "metadata": {},
   "source": [
    "## 4. Recipes5k\n",
    "\n",
    "* **[Recipes5k Dataset](http://www.ub.edu/cvub/recipes5k/)**:\n",
    "\n",
    "The Recipes5k dataset comprises 4,826 recipes featuring images and corresponding ingredient lists, with 3,213 unique ingredients simplified from 1,014 by removing overly-descriptive particles, offering a diverse collection of alternative preparations for each of the 101 food types from Food101, meticulously balanced across training, validation, and test splits. The dataset addresses intra- and inter-class variability, extracted from Yummly with 50 recipes per food type.\n",
    "\n",
    "\n",
    "We'll use the function `get_embeddings_df` to generate the embeddings in `datasets/Recipes5k/images` and store the embeddings in `Embeddings/Recipes5k/Embeddings_Backbone.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae570c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 24\n",
    "dataset = 'Recipes5k'\n",
    "image_col = 'image'\n",
    "text_col = 'ingredients'\n",
    "output_dir = f'Embeddings_vlm/{dataset}'\n",
    "output_file = 'embeddings_clip.csv'\n",
    "\n",
    "dataset_path = f'datasets/{dataset}/'\n",
    "images_dir = 'images/'\n",
    "labels = 'labels.csv'\n",
    "\n",
    "images_path = os.path.join(dataset_path, images_dir)\n",
    "labels_path = os.path.join(dataset_path, labels)\n",
    "\n",
    "df = preprocess_df(df=pd.read_csv(labels_path), image_columns=image_col, images_path=images_path)\n",
    "\n",
    "model.get_embeddings(dataframe=df, batch_size=batch_size, image_col_name=image_col, text_col_name=text_col, output_dir=output_dir, output_file=output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e86334",
   "metadata": {},
   "source": [
    "## 5. BRSET\n",
    "* **[BRSET Dataset](https://physionet.org/content/brazilian-ophthalmological/1.0.0/)**:\n",
    "\n",
    "The Brazilian Multilabel Ophthalmological Dataset (BRSET) stands as a pioneering initiative aimed at bridging the gap in ophthalmological datasets, particularly for under-represented populations in low and medium-income countries. This comprehensive dataset encompasses 16,266 images from 8,524 Brazilian patients, incorporating a wide array of data points including demographics, anatomical parameters of the macula, optic disc, and vessels, along with quality control metrics such as focus, illumination, image field, and artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91fd2a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16266/16266 [00:03<00:00, 4597.47it/s]\n",
      "100%|██████████| 16266/16266 [00:22<00:00, 717.60it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ec1921bb5644299bf8f6c8f1b225960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing batches:   0%|          | 0/678 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>DR_ICDR</th>\n",
       "      <th>text</th>\n",
       "      <th>DR_2</th>\n",
       "      <th>DR_3</th>\n",
       "      <th>split</th>\n",
       "      <th>image_embedding_0</th>\n",
       "      <th>image_embedding_1</th>\n",
       "      <th>image_embedding_2</th>\n",
       "      <th>image_embedding_3</th>\n",
       "      <th>...</th>\n",
       "      <th>text_embedding_502</th>\n",
       "      <th>text_embedding_503</th>\n",
       "      <th>text_embedding_504</th>\n",
       "      <th>text_embedding_505</th>\n",
       "      <th>text_embedding_506</th>\n",
       "      <th>text_embedding_507</th>\n",
       "      <th>text_embedding_508</th>\n",
       "      <th>text_embedding_509</th>\n",
       "      <th>text_embedding_510</th>\n",
       "      <th>text_embedding_511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>datasets/brset/images/img00001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>An image from the right eye of a male patient,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>0.012998</td>\n",
       "      <td>-0.012632</td>\n",
       "      <td>0.010281</td>\n",
       "      <td>0.016375</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054316</td>\n",
       "      <td>0.026362</td>\n",
       "      <td>0.062661</td>\n",
       "      <td>0.023066</td>\n",
       "      <td>-0.023967</td>\n",
       "      <td>-0.013421</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>-0.058343</td>\n",
       "      <td>0.027308</td>\n",
       "      <td>0.011322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>datasets/brset/images/img00002.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>An image from the left eye of a male patient, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>0.013524</td>\n",
       "      <td>-0.017406</td>\n",
       "      <td>0.012482</td>\n",
       "      <td>0.012262</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054454</td>\n",
       "      <td>0.018202</td>\n",
       "      <td>0.061717</td>\n",
       "      <td>0.022467</td>\n",
       "      <td>-0.011161</td>\n",
       "      <td>-0.011376</td>\n",
       "      <td>0.030134</td>\n",
       "      <td>-0.049021</td>\n",
       "      <td>0.021231</td>\n",
       "      <td>0.010651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>datasets/brset/images/img00003.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>An image from the right eye of a female patien...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>0.036357</td>\n",
       "      <td>-0.018087</td>\n",
       "      <td>-0.001801</td>\n",
       "      <td>0.010425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055949</td>\n",
       "      <td>0.011358</td>\n",
       "      <td>0.072995</td>\n",
       "      <td>0.030307</td>\n",
       "      <td>-0.011789</td>\n",
       "      <td>-0.011042</td>\n",
       "      <td>0.042255</td>\n",
       "      <td>-0.057926</td>\n",
       "      <td>0.033326</td>\n",
       "      <td>0.018503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>datasets/brset/images/img00004.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>An image from the left eye of a female patient...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>0.022021</td>\n",
       "      <td>-0.011668</td>\n",
       "      <td>0.010509</td>\n",
       "      <td>0.022121</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055314</td>\n",
       "      <td>0.002594</td>\n",
       "      <td>0.074490</td>\n",
       "      <td>0.034430</td>\n",
       "      <td>-0.000350</td>\n",
       "      <td>-0.007918</td>\n",
       "      <td>0.042707</td>\n",
       "      <td>-0.047150</td>\n",
       "      <td>0.027270</td>\n",
       "      <td>0.020940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>datasets/brset/images/img00005.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>An image from the right eye of a male patient,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>0.018684</td>\n",
       "      <td>-0.010326</td>\n",
       "      <td>0.004721</td>\n",
       "      <td>0.006435</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052848</td>\n",
       "      <td>0.021930</td>\n",
       "      <td>0.068045</td>\n",
       "      <td>0.027663</td>\n",
       "      <td>-0.020903</td>\n",
       "      <td>-0.012616</td>\n",
       "      <td>0.037164</td>\n",
       "      <td>-0.051632</td>\n",
       "      <td>0.033358</td>\n",
       "      <td>0.013019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16261</th>\n",
       "      <td>datasets/brset/images/img16262.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>An image from the left eye of a male patient, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>0.020267</td>\n",
       "      <td>-0.014308</td>\n",
       "      <td>0.007233</td>\n",
       "      <td>0.009556</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051821</td>\n",
       "      <td>0.018065</td>\n",
       "      <td>0.063733</td>\n",
       "      <td>0.028109</td>\n",
       "      <td>-0.009481</td>\n",
       "      <td>-0.011907</td>\n",
       "      <td>0.032493</td>\n",
       "      <td>-0.043669</td>\n",
       "      <td>0.024307</td>\n",
       "      <td>0.012130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16262</th>\n",
       "      <td>datasets/brset/images/img16263.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>An image from the right eye of a male patient,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>0.022504</td>\n",
       "      <td>-0.012735</td>\n",
       "      <td>0.007244</td>\n",
       "      <td>0.008257</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053089</td>\n",
       "      <td>0.022047</td>\n",
       "      <td>0.066592</td>\n",
       "      <td>0.027557</td>\n",
       "      <td>-0.017143</td>\n",
       "      <td>-0.013583</td>\n",
       "      <td>0.038866</td>\n",
       "      <td>-0.059881</td>\n",
       "      <td>0.031864</td>\n",
       "      <td>0.018169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16263</th>\n",
       "      <td>datasets/brset/images/img16264.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>An image from the left eye of a male patient, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>0.020345</td>\n",
       "      <td>-0.018842</td>\n",
       "      <td>0.001421</td>\n",
       "      <td>0.002808</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053673</td>\n",
       "      <td>0.012375</td>\n",
       "      <td>0.067669</td>\n",
       "      <td>0.029927</td>\n",
       "      <td>-0.003204</td>\n",
       "      <td>-0.011643</td>\n",
       "      <td>0.036917</td>\n",
       "      <td>-0.050136</td>\n",
       "      <td>0.027056</td>\n",
       "      <td>0.018447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16264</th>\n",
       "      <td>datasets/brset/images/img16265.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>An image from the right eye of a male patient,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>0.016526</td>\n",
       "      <td>-0.019370</td>\n",
       "      <td>0.002399</td>\n",
       "      <td>0.017877</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.047541</td>\n",
       "      <td>0.028574</td>\n",
       "      <td>0.065664</td>\n",
       "      <td>0.030953</td>\n",
       "      <td>-0.015932</td>\n",
       "      <td>-0.018688</td>\n",
       "      <td>0.031363</td>\n",
       "      <td>-0.038107</td>\n",
       "      <td>0.039231</td>\n",
       "      <td>0.005134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16265</th>\n",
       "      <td>datasets/brset/images/img16266.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>An image from the left eye of a male patient, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>0.031135</td>\n",
       "      <td>-0.020491</td>\n",
       "      <td>0.003028</td>\n",
       "      <td>0.003197</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049115</td>\n",
       "      <td>0.019184</td>\n",
       "      <td>0.065717</td>\n",
       "      <td>0.033278</td>\n",
       "      <td>-0.003479</td>\n",
       "      <td>-0.016959</td>\n",
       "      <td>0.030059</td>\n",
       "      <td>-0.032182</td>\n",
       "      <td>0.035483</td>\n",
       "      <td>0.005845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16266 rows × 1030 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 image_id  DR_ICDR  \\\n",
       "0      datasets/brset/images/img00001.jpg        0   \n",
       "1      datasets/brset/images/img00002.jpg        0   \n",
       "2      datasets/brset/images/img00003.jpg        0   \n",
       "3      datasets/brset/images/img00004.jpg        0   \n",
       "4      datasets/brset/images/img00005.jpg        0   \n",
       "...                                   ...      ...   \n",
       "16261  datasets/brset/images/img16262.jpg        1   \n",
       "16262  datasets/brset/images/img16263.jpg        0   \n",
       "16263  datasets/brset/images/img16264.jpg        0   \n",
       "16264  datasets/brset/images/img16265.jpg        0   \n",
       "16265  datasets/brset/images/img16266.jpg        0   \n",
       "\n",
       "                                                    text  DR_2  DR_3  split  \\\n",
       "0      An image from the right eye of a male patient,...     0     0  train   \n",
       "1      An image from the left eye of a male patient, ...     0     0   test   \n",
       "2      An image from the right eye of a female patien...     0     0  train   \n",
       "3      An image from the left eye of a female patient...     0     0  train   \n",
       "4      An image from the right eye of a male patient,...     0     0   test   \n",
       "...                                                  ...   ...   ...    ...   \n",
       "16261  An image from the left eye of a male patient, ...     1     1   test   \n",
       "16262  An image from the right eye of a male patient,...     0     0  train   \n",
       "16263  An image from the left eye of a male patient, ...     0     0   test   \n",
       "16264  An image from the right eye of a male patient,...     0     0  train   \n",
       "16265  An image from the left eye of a male patient, ...     0     0  train   \n",
       "\n",
       "       image_embedding_0  image_embedding_1  image_embedding_2  \\\n",
       "0               0.012998          -0.012632           0.010281   \n",
       "1               0.013524          -0.017406           0.012482   \n",
       "2               0.036357          -0.018087          -0.001801   \n",
       "3               0.022021          -0.011668           0.010509   \n",
       "4               0.018684          -0.010326           0.004721   \n",
       "...                  ...                ...                ...   \n",
       "16261           0.020267          -0.014308           0.007233   \n",
       "16262           0.022504          -0.012735           0.007244   \n",
       "16263           0.020345          -0.018842           0.001421   \n",
       "16264           0.016526          -0.019370           0.002399   \n",
       "16265           0.031135          -0.020491           0.003028   \n",
       "\n",
       "       image_embedding_3  ...  text_embedding_502  text_embedding_503  \\\n",
       "0               0.016375  ...           -0.054316            0.026362   \n",
       "1               0.012262  ...           -0.054454            0.018202   \n",
       "2               0.010425  ...           -0.055949            0.011358   \n",
       "3               0.022121  ...           -0.055314            0.002594   \n",
       "4               0.006435  ...           -0.052848            0.021930   \n",
       "...                  ...  ...                 ...                 ...   \n",
       "16261           0.009556  ...           -0.051821            0.018065   \n",
       "16262           0.008257  ...           -0.053089            0.022047   \n",
       "16263           0.002808  ...           -0.053673            0.012375   \n",
       "16264           0.017877  ...           -0.047541            0.028574   \n",
       "16265           0.003197  ...           -0.049115            0.019184   \n",
       "\n",
       "       text_embedding_504  text_embedding_505  text_embedding_506  \\\n",
       "0                0.062661            0.023066           -0.023967   \n",
       "1                0.061717            0.022467           -0.011161   \n",
       "2                0.072995            0.030307           -0.011789   \n",
       "3                0.074490            0.034430           -0.000350   \n",
       "4                0.068045            0.027663           -0.020903   \n",
       "...                   ...                 ...                 ...   \n",
       "16261            0.063733            0.028109           -0.009481   \n",
       "16262            0.066592            0.027557           -0.017143   \n",
       "16263            0.067669            0.029927           -0.003204   \n",
       "16264            0.065664            0.030953           -0.015932   \n",
       "16265            0.065717            0.033278           -0.003479   \n",
       "\n",
       "       text_embedding_507  text_embedding_508  text_embedding_509  \\\n",
       "0               -0.013421            0.033898           -0.058343   \n",
       "1               -0.011376            0.030134           -0.049021   \n",
       "2               -0.011042            0.042255           -0.057926   \n",
       "3               -0.007918            0.042707           -0.047150   \n",
       "4               -0.012616            0.037164           -0.051632   \n",
       "...                   ...                 ...                 ...   \n",
       "16261           -0.011907            0.032493           -0.043669   \n",
       "16262           -0.013583            0.038866           -0.059881   \n",
       "16263           -0.011643            0.036917           -0.050136   \n",
       "16264           -0.018688            0.031363           -0.038107   \n",
       "16265           -0.016959            0.030059           -0.032182   \n",
       "\n",
       "       text_embedding_510  text_embedding_511  \n",
       "0                0.027308            0.011322  \n",
       "1                0.021231            0.010651  \n",
       "2                0.033326            0.018503  \n",
       "3                0.027270            0.020940  \n",
       "4                0.033358            0.013019  \n",
       "...                   ...                 ...  \n",
       "16261            0.024307            0.012130  \n",
       "16262            0.031864            0.018169  \n",
       "16263            0.027056            0.018447  \n",
       "16264            0.039231            0.005134  \n",
       "16265            0.035483            0.005845  \n",
       "\n",
       "[16266 rows x 1030 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 24\n",
    "dataset = 'brset'\n",
    "image_col = 'image_id'\n",
    "text_col = 'text'\n",
    "output_dir = f'Embeddings_vlm/{dataset}'\n",
    "output_file = 'embeddings_clip.csv'\n",
    "\n",
    "dataset_path = f'datasets/{dataset}/'\n",
    "images_dir = 'images/'\n",
    "labels = 'labels.csv'\n",
    "\n",
    "images_path = os.path.join(dataset_path, images_dir)\n",
    "labels_path = os.path.join(dataset_path, labels)\n",
    "\n",
    "df = preprocess_df(df=pd.read_csv(labels_path), image_columns=image_col, images_path=images_path)\n",
    "\n",
    "model.get_embeddings(dataframe=df, batch_size=batch_size, image_col_name=image_col, text_col_name=text_col, output_dir=output_dir, output_file=output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd6584b",
   "metadata": {},
   "source": [
    "### 6. HAM10000 dataset\n",
    "\n",
    "* [HAM10000 dataset](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/DBW86T)\n",
    "\n",
    "The MNIST: HAM10000 dataset is a large collection of dermatoscopic images from different populations, acquired and stored by the Department of Dermatology at the Medical University of Vienna, Austria. It consists of 10,015 dermatoscopic images which can serve as a training set for academic machine learning purposes in tasks like skin lesion analysis and classification, specifically focusing on the detection of melanoma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b696e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10015 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|██████████| 10015/10015 [00:02<00:00, 4579.94it/s]\n",
      "100%|██████████| 10015/10015 [00:01<00:00, 6417.42it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fa0d42a466c4eb78bb362540f4a9d3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing batches:   0%|          | 0/418 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>text</th>\n",
       "      <th>split</th>\n",
       "      <th>image_embedding_0</th>\n",
       "      <th>image_embedding_1</th>\n",
       "      <th>image_embedding_2</th>\n",
       "      <th>image_embedding_3</th>\n",
       "      <th>image_embedding_4</th>\n",
       "      <th>image_embedding_5</th>\n",
       "      <th>...</th>\n",
       "      <th>text_embedding_502</th>\n",
       "      <th>text_embedding_503</th>\n",
       "      <th>text_embedding_504</th>\n",
       "      <th>text_embedding_505</th>\n",
       "      <th>text_embedding_506</th>\n",
       "      <th>text_embedding_507</th>\n",
       "      <th>text_embedding_508</th>\n",
       "      <th>text_embedding_509</th>\n",
       "      <th>text_embedding_510</th>\n",
       "      <th>text_embedding_511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>datasets/ham10000/images/ISIC_0033319.jpg</td>\n",
       "      <td>nv</td>\n",
       "      <td>Patient diagnosed via histo. Age: 35 years. Se...</td>\n",
       "      <td>train</td>\n",
       "      <td>0.017459</td>\n",
       "      <td>-0.006133</td>\n",
       "      <td>0.042509</td>\n",
       "      <td>0.032119</td>\n",
       "      <td>-0.020298</td>\n",
       "      <td>-0.029999</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085103</td>\n",
       "      <td>-0.035549</td>\n",
       "      <td>0.022616</td>\n",
       "      <td>0.014842</td>\n",
       "      <td>-0.010682</td>\n",
       "      <td>0.007425</td>\n",
       "      <td>-0.010183</td>\n",
       "      <td>0.059058</td>\n",
       "      <td>0.028891</td>\n",
       "      <td>0.073401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>datasets/ham10000/images/ISIC_0030823.jpg</td>\n",
       "      <td>nv</td>\n",
       "      <td>Patient diagnosed via follow_up. Age: 40 years...</td>\n",
       "      <td>train</td>\n",
       "      <td>0.013314</td>\n",
       "      <td>-0.004718</td>\n",
       "      <td>0.036896</td>\n",
       "      <td>0.013657</td>\n",
       "      <td>-0.018710</td>\n",
       "      <td>-0.000790</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024121</td>\n",
       "      <td>0.001504</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.028216</td>\n",
       "      <td>-0.033343</td>\n",
       "      <td>-0.007173</td>\n",
       "      <td>0.025764</td>\n",
       "      <td>0.037911</td>\n",
       "      <td>-0.028967</td>\n",
       "      <td>0.032034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>datasets/ham10000/images/ISIC_0028730.jpg</td>\n",
       "      <td>akiec</td>\n",
       "      <td>Patient diagnosed via histo. Age: 65 years. Se...</td>\n",
       "      <td>train</td>\n",
       "      <td>0.023076</td>\n",
       "      <td>-0.006460</td>\n",
       "      <td>0.046531</td>\n",
       "      <td>-0.007525</td>\n",
       "      <td>-0.052272</td>\n",
       "      <td>0.024759</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.076046</td>\n",
       "      <td>-0.025927</td>\n",
       "      <td>0.019258</td>\n",
       "      <td>0.013950</td>\n",
       "      <td>-0.013910</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>-0.016514</td>\n",
       "      <td>0.060165</td>\n",
       "      <td>0.028732</td>\n",
       "      <td>0.068683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>datasets/ham10000/images/ISIC_0027299.jpg</td>\n",
       "      <td>nv</td>\n",
       "      <td>Patient diagnosed via follow_up. Age: 40 years...</td>\n",
       "      <td>train</td>\n",
       "      <td>0.002341</td>\n",
       "      <td>-0.042092</td>\n",
       "      <td>0.056254</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>-0.013943</td>\n",
       "      <td>0.011410</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017013</td>\n",
       "      <td>-0.020450</td>\n",
       "      <td>0.020093</td>\n",
       "      <td>0.021699</td>\n",
       "      <td>-0.018428</td>\n",
       "      <td>0.018907</td>\n",
       "      <td>0.022027</td>\n",
       "      <td>0.045309</td>\n",
       "      <td>-0.014772</td>\n",
       "      <td>0.017288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>datasets/ham10000/images/ISIC_0032444.jpg</td>\n",
       "      <td>nv</td>\n",
       "      <td>Patient diagnosed via histo. Age: 65 years. Se...</td>\n",
       "      <td>train</td>\n",
       "      <td>0.012029</td>\n",
       "      <td>-0.003644</td>\n",
       "      <td>0.028491</td>\n",
       "      <td>0.017455</td>\n",
       "      <td>-0.017562</td>\n",
       "      <td>-0.005040</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093017</td>\n",
       "      <td>-0.022929</td>\n",
       "      <td>0.013042</td>\n",
       "      <td>0.007998</td>\n",
       "      <td>-0.020830</td>\n",
       "      <td>-0.015631</td>\n",
       "      <td>-0.007309</td>\n",
       "      <td>0.057171</td>\n",
       "      <td>0.030297</td>\n",
       "      <td>0.068561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10010</th>\n",
       "      <td>datasets/ham10000/images/ISIC_0034116.jpg</td>\n",
       "      <td>nv</td>\n",
       "      <td>Patient diagnosed via histo. Age: 35 years. Se...</td>\n",
       "      <td>test</td>\n",
       "      <td>0.034317</td>\n",
       "      <td>-0.005902</td>\n",
       "      <td>0.033596</td>\n",
       "      <td>0.013734</td>\n",
       "      <td>-0.001983</td>\n",
       "      <td>0.006587</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.089331</td>\n",
       "      <td>-0.024633</td>\n",
       "      <td>0.013912</td>\n",
       "      <td>0.015758</td>\n",
       "      <td>-0.022870</td>\n",
       "      <td>-0.014493</td>\n",
       "      <td>-0.007229</td>\n",
       "      <td>0.065375</td>\n",
       "      <td>0.024135</td>\n",
       "      <td>0.075245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10011</th>\n",
       "      <td>datasets/ham10000/images/ISIC_0026453.jpg</td>\n",
       "      <td>bcc</td>\n",
       "      <td>Patient diagnosed via histo. Age: 55 years. Se...</td>\n",
       "      <td>test</td>\n",
       "      <td>0.039306</td>\n",
       "      <td>-0.022963</td>\n",
       "      <td>0.006208</td>\n",
       "      <td>0.007151</td>\n",
       "      <td>-0.000994</td>\n",
       "      <td>0.003135</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.092979</td>\n",
       "      <td>-0.026890</td>\n",
       "      <td>0.015404</td>\n",
       "      <td>0.007477</td>\n",
       "      <td>-0.018264</td>\n",
       "      <td>-0.009003</td>\n",
       "      <td>-0.005414</td>\n",
       "      <td>0.054793</td>\n",
       "      <td>0.026829</td>\n",
       "      <td>0.066075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10012</th>\n",
       "      <td>datasets/ham10000/images/ISIC_0029885.jpg</td>\n",
       "      <td>mel</td>\n",
       "      <td>Patient diagnosed via histo. Age: 35 years. Se...</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.007351</td>\n",
       "      <td>-0.020153</td>\n",
       "      <td>0.009813</td>\n",
       "      <td>-0.022048</td>\n",
       "      <td>-0.008027</td>\n",
       "      <td>0.006708</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.101426</td>\n",
       "      <td>-0.029974</td>\n",
       "      <td>0.016112</td>\n",
       "      <td>0.007236</td>\n",
       "      <td>-0.021058</td>\n",
       "      <td>-0.013079</td>\n",
       "      <td>-0.002877</td>\n",
       "      <td>0.057138</td>\n",
       "      <td>0.029186</td>\n",
       "      <td>0.076712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10013</th>\n",
       "      <td>datasets/ham10000/images/ISIC_0033226.jpg</td>\n",
       "      <td>mel</td>\n",
       "      <td>Patient diagnosed via histo. Age: 65 years. Se...</td>\n",
       "      <td>test</td>\n",
       "      <td>0.010150</td>\n",
       "      <td>-0.013687</td>\n",
       "      <td>0.011988</td>\n",
       "      <td>0.025662</td>\n",
       "      <td>0.002185</td>\n",
       "      <td>-0.017817</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080767</td>\n",
       "      <td>-0.036380</td>\n",
       "      <td>0.022734</td>\n",
       "      <td>0.016851</td>\n",
       "      <td>-0.005421</td>\n",
       "      <td>0.005429</td>\n",
       "      <td>-0.022412</td>\n",
       "      <td>0.060543</td>\n",
       "      <td>0.029883</td>\n",
       "      <td>0.065808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10014</th>\n",
       "      <td>datasets/ham10000/images/ISIC_0033065.jpg</td>\n",
       "      <td>nv</td>\n",
       "      <td>Patient diagnosed via consensus. Age: No data ...</td>\n",
       "      <td>test</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.011533</td>\n",
       "      <td>0.025216</td>\n",
       "      <td>0.013250</td>\n",
       "      <td>-0.017564</td>\n",
       "      <td>-0.011585</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013048</td>\n",
       "      <td>0.011393</td>\n",
       "      <td>0.020653</td>\n",
       "      <td>0.022281</td>\n",
       "      <td>-0.017259</td>\n",
       "      <td>-0.014341</td>\n",
       "      <td>-0.011676</td>\n",
       "      <td>0.053047</td>\n",
       "      <td>-0.012525</td>\n",
       "      <td>-0.009116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10015 rows × 1028 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        image_id     dx  \\\n",
       "0      datasets/ham10000/images/ISIC_0033319.jpg     nv   \n",
       "1      datasets/ham10000/images/ISIC_0030823.jpg     nv   \n",
       "2      datasets/ham10000/images/ISIC_0028730.jpg  akiec   \n",
       "3      datasets/ham10000/images/ISIC_0027299.jpg     nv   \n",
       "4      datasets/ham10000/images/ISIC_0032444.jpg     nv   \n",
       "...                                          ...    ...   \n",
       "10010  datasets/ham10000/images/ISIC_0034116.jpg     nv   \n",
       "10011  datasets/ham10000/images/ISIC_0026453.jpg    bcc   \n",
       "10012  datasets/ham10000/images/ISIC_0029885.jpg    mel   \n",
       "10013  datasets/ham10000/images/ISIC_0033226.jpg    mel   \n",
       "10014  datasets/ham10000/images/ISIC_0033065.jpg     nv   \n",
       "\n",
       "                                                    text  split  \\\n",
       "0      Patient diagnosed via histo. Age: 35 years. Se...  train   \n",
       "1      Patient diagnosed via follow_up. Age: 40 years...  train   \n",
       "2      Patient diagnosed via histo. Age: 65 years. Se...  train   \n",
       "3      Patient diagnosed via follow_up. Age: 40 years...  train   \n",
       "4      Patient diagnosed via histo. Age: 65 years. Se...  train   \n",
       "...                                                  ...    ...   \n",
       "10010  Patient diagnosed via histo. Age: 35 years. Se...   test   \n",
       "10011  Patient diagnosed via histo. Age: 55 years. Se...   test   \n",
       "10012  Patient diagnosed via histo. Age: 35 years. Se...   test   \n",
       "10013  Patient diagnosed via histo. Age: 65 years. Se...   test   \n",
       "10014  Patient diagnosed via consensus. Age: No data ...   test   \n",
       "\n",
       "       image_embedding_0  image_embedding_1  image_embedding_2  \\\n",
       "0               0.017459          -0.006133           0.042509   \n",
       "1               0.013314          -0.004718           0.036896   \n",
       "2               0.023076          -0.006460           0.046531   \n",
       "3               0.002341          -0.042092           0.056254   \n",
       "4               0.012029          -0.003644           0.028491   \n",
       "...                  ...                ...                ...   \n",
       "10010           0.034317          -0.005902           0.033596   \n",
       "10011           0.039306          -0.022963           0.006208   \n",
       "10012          -0.007351          -0.020153           0.009813   \n",
       "10013           0.010150          -0.013687           0.011988   \n",
       "10014           0.000463           0.011533           0.025216   \n",
       "\n",
       "       image_embedding_3  image_embedding_4  image_embedding_5  ...  \\\n",
       "0               0.032119          -0.020298          -0.029999  ...   \n",
       "1               0.013657          -0.018710          -0.000790  ...   \n",
       "2              -0.007525          -0.052272           0.024759  ...   \n",
       "3               0.000176          -0.013943           0.011410  ...   \n",
       "4               0.017455          -0.017562          -0.005040  ...   \n",
       "...                  ...                ...                ...  ...   \n",
       "10010           0.013734          -0.001983           0.006587  ...   \n",
       "10011           0.007151          -0.000994           0.003135  ...   \n",
       "10012          -0.022048          -0.008027           0.006708  ...   \n",
       "10013           0.025662           0.002185          -0.017817  ...   \n",
       "10014           0.013250          -0.017564          -0.011585  ...   \n",
       "\n",
       "       text_embedding_502  text_embedding_503  text_embedding_504  \\\n",
       "0               -0.085103           -0.035549            0.022616   \n",
       "1               -0.024121            0.001504            0.007381   \n",
       "2               -0.076046           -0.025927            0.019258   \n",
       "3               -0.017013           -0.020450            0.020093   \n",
       "4               -0.093017           -0.022929            0.013042   \n",
       "...                   ...                 ...                 ...   \n",
       "10010           -0.089331           -0.024633            0.013912   \n",
       "10011           -0.092979           -0.026890            0.015404   \n",
       "10012           -0.101426           -0.029974            0.016112   \n",
       "10013           -0.080767           -0.036380            0.022734   \n",
       "10014           -0.013048            0.011393            0.020653   \n",
       "\n",
       "       text_embedding_505  text_embedding_506  text_embedding_507  \\\n",
       "0                0.014842           -0.010682            0.007425   \n",
       "1                0.028216           -0.033343           -0.007173   \n",
       "2                0.013950           -0.013910            0.000220   \n",
       "3                0.021699           -0.018428            0.018907   \n",
       "4                0.007998           -0.020830           -0.015631   \n",
       "...                   ...                 ...                 ...   \n",
       "10010            0.015758           -0.022870           -0.014493   \n",
       "10011            0.007477           -0.018264           -0.009003   \n",
       "10012            0.007236           -0.021058           -0.013079   \n",
       "10013            0.016851           -0.005421            0.005429   \n",
       "10014            0.022281           -0.017259           -0.014341   \n",
       "\n",
       "       text_embedding_508  text_embedding_509  text_embedding_510  \\\n",
       "0               -0.010183            0.059058            0.028891   \n",
       "1                0.025764            0.037911           -0.028967   \n",
       "2               -0.016514            0.060165            0.028732   \n",
       "3                0.022027            0.045309           -0.014772   \n",
       "4               -0.007309            0.057171            0.030297   \n",
       "...                   ...                 ...                 ...   \n",
       "10010           -0.007229            0.065375            0.024135   \n",
       "10011           -0.005414            0.054793            0.026829   \n",
       "10012           -0.002877            0.057138            0.029186   \n",
       "10013           -0.022412            0.060543            0.029883   \n",
       "10014           -0.011676            0.053047           -0.012525   \n",
       "\n",
       "       text_embedding_511  \n",
       "0                0.073401  \n",
       "1                0.032034  \n",
       "2                0.068683  \n",
       "3                0.017288  \n",
       "4                0.068561  \n",
       "...                   ...  \n",
       "10010            0.075245  \n",
       "10011            0.066075  \n",
       "10012            0.076712  \n",
       "10013            0.065808  \n",
       "10014           -0.009116  \n",
       "\n",
       "[10015 rows x 1028 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 24\n",
    "dataset = 'ham10000'\n",
    "image_col = 'image_id'\n",
    "text_col = 'text'\n",
    "output_dir = f'Embeddings_vlm/{dataset}'\n",
    "output_file = 'embeddings_clip.csv'\n",
    "\n",
    "dataset_path = f'datasets/{dataset}/'\n",
    "images_dir = 'images/'\n",
    "labels = 'labels.csv'\n",
    "\n",
    "images_path = os.path.join(dataset_path, images_dir)\n",
    "labels_path = os.path.join(dataset_path, labels)\n",
    "\n",
    "df = preprocess_df(df=pd.read_csv(labels_path), image_columns=image_col, images_path=images_path)\n",
    "\n",
    "model.get_embeddings(dataframe=df, batch_size=batch_size, image_col_name=image_col, text_col_name=text_col, output_dir=output_dir, output_file=output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cd757b",
   "metadata": {},
   "source": [
    "## 7. Colombian Multimodal Satellite dataset\n",
    "* **[A Multi-Modal Satellite Imagery Dataset for Public Health Analysis in Colombia](https://physionet.org/content/multimodal-satellite-data/1.0.0/)**:\n",
    "\n",
    "The Multi-Modal Satellite Imagery Dataset in Colombia integrates economic, demographic, meteorological, and epidemiological data. It comprises 12,636 high-quality satellite images from 81 municipalities between 2016 and 2018, with minimal cloud cover. Its applications include deforestation monitoring, education indices forecasting, water quality assessment, extreme climatic event tracking, epidemic illness addressing, and precision agriculture optimization. We'll use it shortly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a885de05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1560/1560 [00:01<00:00, 804.88it/s]\n",
      "100%|██████████| 1560/1560 [00:01<00:00, 1367.35it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b12f6382b624510ba9ad38c0079e615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing batches:   0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>text</th>\n",
       "      <th>Labels</th>\n",
       "      <th>split</th>\n",
       "      <th>image_embedding_0</th>\n",
       "      <th>image_embedding_1</th>\n",
       "      <th>image_embedding_2</th>\n",
       "      <th>image_embedding_3</th>\n",
       "      <th>image_embedding_4</th>\n",
       "      <th>image_embedding_5</th>\n",
       "      <th>...</th>\n",
       "      <th>text_embedding_502</th>\n",
       "      <th>text_embedding_503</th>\n",
       "      <th>text_embedding_504</th>\n",
       "      <th>text_embedding_505</th>\n",
       "      <th>text_embedding_506</th>\n",
       "      <th>text_embedding_507</th>\n",
       "      <th>text_embedding_508</th>\n",
       "      <th>text_embedding_509</th>\n",
       "      <th>text_embedding_510</th>\n",
       "      <th>text_embedding_511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>datasets/satellitedata/images/73001_2016-06-12...</td>\n",
       "      <td>An image from city Ibagué taken in date 2016-0...</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>-0.000648</td>\n",
       "      <td>0.047631</td>\n",
       "      <td>-0.007688</td>\n",
       "      <td>-0.015954</td>\n",
       "      <td>0.033954</td>\n",
       "      <td>-0.024987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003876</td>\n",
       "      <td>-0.020030</td>\n",
       "      <td>0.014448</td>\n",
       "      <td>0.025682</td>\n",
       "      <td>0.010953</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.021032</td>\n",
       "      <td>0.009018</td>\n",
       "      <td>0.002254</td>\n",
       "      <td>-0.014104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>datasets/satellitedata/images/76001_2017-06-11...</td>\n",
       "      <td>An image from city Cali taken in date 2017-06-...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.017359</td>\n",
       "      <td>0.030042</td>\n",
       "      <td>0.016325</td>\n",
       "      <td>-0.010410</td>\n",
       "      <td>0.046289</td>\n",
       "      <td>-0.025459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019132</td>\n",
       "      <td>-0.028726</td>\n",
       "      <td>0.012622</td>\n",
       "      <td>0.030623</td>\n",
       "      <td>0.007002</td>\n",
       "      <td>0.006732</td>\n",
       "      <td>0.010945</td>\n",
       "      <td>-0.010793</td>\n",
       "      <td>-0.000270</td>\n",
       "      <td>-0.012476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>datasets/satellitedata/images/8001_2018-04-15.jpg</td>\n",
       "      <td>An image from city Barranquilla taken in date ...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>-0.022790</td>\n",
       "      <td>0.021263</td>\n",
       "      <td>0.040344</td>\n",
       "      <td>-0.016606</td>\n",
       "      <td>0.041269</td>\n",
       "      <td>-0.028196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014796</td>\n",
       "      <td>-0.006373</td>\n",
       "      <td>-0.014684</td>\n",
       "      <td>0.023051</td>\n",
       "      <td>0.005047</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.005979</td>\n",
       "      <td>-0.020611</td>\n",
       "      <td>-0.006694</td>\n",
       "      <td>0.008903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>datasets/satellitedata/images/23001_2016-05-08...</td>\n",
       "      <td>An image from city Montería taken in date 2016...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>-0.013127</td>\n",
       "      <td>-0.022996</td>\n",
       "      <td>-0.049374</td>\n",
       "      <td>-0.006306</td>\n",
       "      <td>0.013601</td>\n",
       "      <td>-0.003762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013533</td>\n",
       "      <td>-0.003991</td>\n",
       "      <td>-0.011703</td>\n",
       "      <td>0.025439</td>\n",
       "      <td>0.004510</td>\n",
       "      <td>-0.007244</td>\n",
       "      <td>0.005063</td>\n",
       "      <td>0.042533</td>\n",
       "      <td>-0.002328</td>\n",
       "      <td>-0.006062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>datasets/satellitedata/images/5001_2017-04-30.jpg</td>\n",
       "      <td>An image from city Medellín taken in date 2017...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>-0.034772</td>\n",
       "      <td>0.040687</td>\n",
       "      <td>0.007086</td>\n",
       "      <td>-0.026446</td>\n",
       "      <td>0.017892</td>\n",
       "      <td>-0.021177</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015247</td>\n",
       "      <td>-0.008037</td>\n",
       "      <td>0.022611</td>\n",
       "      <td>0.020556</td>\n",
       "      <td>0.020584</td>\n",
       "      <td>-0.001789</td>\n",
       "      <td>0.015643</td>\n",
       "      <td>-0.005070</td>\n",
       "      <td>0.008810</td>\n",
       "      <td>0.005491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1555</th>\n",
       "      <td>datasets/satellitedata/images/50001_2017-03-19...</td>\n",
       "      <td>An image from city Villavicencio taken in date...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>0.011827</td>\n",
       "      <td>-0.015805</td>\n",
       "      <td>-0.005934</td>\n",
       "      <td>-0.023800</td>\n",
       "      <td>0.020632</td>\n",
       "      <td>-0.012690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007440</td>\n",
       "      <td>-0.015429</td>\n",
       "      <td>0.006488</td>\n",
       "      <td>0.032507</td>\n",
       "      <td>0.011390</td>\n",
       "      <td>-0.019991</td>\n",
       "      <td>0.025756</td>\n",
       "      <td>-0.001323</td>\n",
       "      <td>-0.010401</td>\n",
       "      <td>-0.010772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1556</th>\n",
       "      <td>datasets/satellitedata/images/23001_2017-03-26...</td>\n",
       "      <td>An image from city Montería taken in date 2017...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.013127</td>\n",
       "      <td>-0.022996</td>\n",
       "      <td>-0.049374</td>\n",
       "      <td>-0.006306</td>\n",
       "      <td>0.013601</td>\n",
       "      <td>-0.003762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014595</td>\n",
       "      <td>-0.012074</td>\n",
       "      <td>-0.008773</td>\n",
       "      <td>0.026105</td>\n",
       "      <td>0.002282</td>\n",
       "      <td>-0.001614</td>\n",
       "      <td>0.008737</td>\n",
       "      <td>0.028377</td>\n",
       "      <td>-0.004192</td>\n",
       "      <td>-0.003824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1557</th>\n",
       "      <td>datasets/satellitedata/images/8001_2017-01-22.jpg</td>\n",
       "      <td>An image from city Barranquilla taken in date ...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.013127</td>\n",
       "      <td>-0.022996</td>\n",
       "      <td>-0.049374</td>\n",
       "      <td>-0.006306</td>\n",
       "      <td>0.013601</td>\n",
       "      <td>-0.003762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015668</td>\n",
       "      <td>-0.014151</td>\n",
       "      <td>-0.005850</td>\n",
       "      <td>0.026696</td>\n",
       "      <td>0.014855</td>\n",
       "      <td>-0.003303</td>\n",
       "      <td>0.007501</td>\n",
       "      <td>-0.014224</td>\n",
       "      <td>-0.006461</td>\n",
       "      <td>0.009316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1558</th>\n",
       "      <td>datasets/satellitedata/images/76001_2017-09-10...</td>\n",
       "      <td>An image from city Cali taken in date 2017-09-...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>0.008757</td>\n",
       "      <td>-0.000926</td>\n",
       "      <td>0.009275</td>\n",
       "      <td>-0.006556</td>\n",
       "      <td>0.058230</td>\n",
       "      <td>-0.016975</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016767</td>\n",
       "      <td>-0.032829</td>\n",
       "      <td>0.012773</td>\n",
       "      <td>0.030282</td>\n",
       "      <td>0.012048</td>\n",
       "      <td>0.008870</td>\n",
       "      <td>0.012012</td>\n",
       "      <td>-0.005184</td>\n",
       "      <td>-0.003771</td>\n",
       "      <td>-0.007549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559</th>\n",
       "      <td>datasets/satellitedata/images/54001_2016-09-18...</td>\n",
       "      <td>An image from city Cúcuta taken in date 2016-0...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.008553</td>\n",
       "      <td>0.014835</td>\n",
       "      <td>0.010155</td>\n",
       "      <td>-0.041346</td>\n",
       "      <td>0.055112</td>\n",
       "      <td>-0.017501</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009146</td>\n",
       "      <td>-0.019846</td>\n",
       "      <td>-0.008351</td>\n",
       "      <td>0.027345</td>\n",
       "      <td>0.022290</td>\n",
       "      <td>-0.015304</td>\n",
       "      <td>0.017576</td>\n",
       "      <td>0.005099</td>\n",
       "      <td>-0.002028</td>\n",
       "      <td>0.002233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1560 rows × 1028 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image_id  \\\n",
       "0     datasets/satellitedata/images/73001_2016-06-12...   \n",
       "1     datasets/satellitedata/images/76001_2017-06-11...   \n",
       "2     datasets/satellitedata/images/8001_2018-04-15.jpg   \n",
       "3     datasets/satellitedata/images/23001_2016-05-08...   \n",
       "4     datasets/satellitedata/images/5001_2017-04-30.jpg   \n",
       "...                                                 ...   \n",
       "1555  datasets/satellitedata/images/50001_2017-03-19...   \n",
       "1556  datasets/satellitedata/images/23001_2017-03-26...   \n",
       "1557  datasets/satellitedata/images/8001_2017-01-22.jpg   \n",
       "1558  datasets/satellitedata/images/76001_2017-09-10...   \n",
       "1559  datasets/satellitedata/images/54001_2016-09-18...   \n",
       "\n",
       "                                                   text  Labels  split  \\\n",
       "0     An image from city Ibagué taken in date 2016-0...       3  train   \n",
       "1     An image from city Cali taken in date 2017-06-...       1  train   \n",
       "2     An image from city Barranquilla taken in date ...       1  train   \n",
       "3     An image from city Montería taken in date 2016...       1  train   \n",
       "4     An image from city Medellín taken in date 2017...       1  train   \n",
       "...                                                 ...     ...    ...   \n",
       "1555  An image from city Villavicencio taken in date...       1   test   \n",
       "1556  An image from city Montería taken in date 2017...       0   test   \n",
       "1557  An image from city Barranquilla taken in date ...       0   test   \n",
       "1558  An image from city Cali taken in date 2017-09-...       0   test   \n",
       "1559  An image from city Cúcuta taken in date 2016-0...       1   test   \n",
       "\n",
       "      image_embedding_0  image_embedding_1  image_embedding_2  \\\n",
       "0             -0.000648           0.047631          -0.007688   \n",
       "1              0.017359           0.030042           0.016325   \n",
       "2             -0.022790           0.021263           0.040344   \n",
       "3             -0.013127          -0.022996          -0.049374   \n",
       "4             -0.034772           0.040687           0.007086   \n",
       "...                 ...                ...                ...   \n",
       "1555           0.011827          -0.015805          -0.005934   \n",
       "1556          -0.013127          -0.022996          -0.049374   \n",
       "1557          -0.013127          -0.022996          -0.049374   \n",
       "1558           0.008757          -0.000926           0.009275   \n",
       "1559          -0.008553           0.014835           0.010155   \n",
       "\n",
       "      image_embedding_3  image_embedding_4  image_embedding_5  ...  \\\n",
       "0             -0.015954           0.033954          -0.024987  ...   \n",
       "1             -0.010410           0.046289          -0.025459  ...   \n",
       "2             -0.016606           0.041269          -0.028196  ...   \n",
       "3             -0.006306           0.013601          -0.003762  ...   \n",
       "4             -0.026446           0.017892          -0.021177  ...   \n",
       "...                 ...                ...                ...  ...   \n",
       "1555          -0.023800           0.020632          -0.012690  ...   \n",
       "1556          -0.006306           0.013601          -0.003762  ...   \n",
       "1557          -0.006306           0.013601          -0.003762  ...   \n",
       "1558          -0.006556           0.058230          -0.016975  ...   \n",
       "1559          -0.041346           0.055112          -0.017501  ...   \n",
       "\n",
       "      text_embedding_502  text_embedding_503  text_embedding_504  \\\n",
       "0               0.003876           -0.020030            0.014448   \n",
       "1               0.019132           -0.028726            0.012622   \n",
       "2               0.014796           -0.006373           -0.014684   \n",
       "3               0.013533           -0.003991           -0.011703   \n",
       "4               0.015247           -0.008037            0.022611   \n",
       "...                  ...                 ...                 ...   \n",
       "1555            0.007440           -0.015429            0.006488   \n",
       "1556            0.014595           -0.012074           -0.008773   \n",
       "1557            0.015668           -0.014151           -0.005850   \n",
       "1558            0.016767           -0.032829            0.012773   \n",
       "1559            0.009146           -0.019846           -0.008351   \n",
       "\n",
       "      text_embedding_505  text_embedding_506  text_embedding_507  \\\n",
       "0               0.025682            0.010953            0.002404   \n",
       "1               0.030623            0.007002            0.006732   \n",
       "2               0.023051            0.005047            0.000785   \n",
       "3               0.025439            0.004510           -0.007244   \n",
       "4               0.020556            0.020584           -0.001789   \n",
       "...                  ...                 ...                 ...   \n",
       "1555            0.032507            0.011390           -0.019991   \n",
       "1556            0.026105            0.002282           -0.001614   \n",
       "1557            0.026696            0.014855           -0.003303   \n",
       "1558            0.030282            0.012048            0.008870   \n",
       "1559            0.027345            0.022290           -0.015304   \n",
       "\n",
       "      text_embedding_508  text_embedding_509  text_embedding_510  \\\n",
       "0               0.021032            0.009018            0.002254   \n",
       "1               0.010945           -0.010793           -0.000270   \n",
       "2               0.005979           -0.020611           -0.006694   \n",
       "3               0.005063            0.042533           -0.002328   \n",
       "4               0.015643           -0.005070            0.008810   \n",
       "...                  ...                 ...                 ...   \n",
       "1555            0.025756           -0.001323           -0.010401   \n",
       "1556            0.008737            0.028377           -0.004192   \n",
       "1557            0.007501           -0.014224           -0.006461   \n",
       "1558            0.012012           -0.005184           -0.003771   \n",
       "1559            0.017576            0.005099           -0.002028   \n",
       "\n",
       "      text_embedding_511  \n",
       "0              -0.014104  \n",
       "1              -0.012476  \n",
       "2               0.008903  \n",
       "3              -0.006062  \n",
       "4               0.005491  \n",
       "...                  ...  \n",
       "1555           -0.010772  \n",
       "1556           -0.003824  \n",
       "1557            0.009316  \n",
       "1558           -0.007549  \n",
       "1559            0.002233  \n",
       "\n",
       "[1560 rows x 1028 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 24\n",
    "dataset = 'satellitedata'\n",
    "image_col = 'image_id'\n",
    "text_col = 'text'\n",
    "output_dir = f'Embeddings_vlm/{dataset}'\n",
    "output_file = 'embeddings_clip.csv'\n",
    "\n",
    "dataset_path = f'datasets/{dataset}/'\n",
    "images_dir = 'images/'\n",
    "labels = 'labels.csv'\n",
    "\n",
    "images_path = os.path.join(dataset_path, images_dir)\n",
    "labels_path = os.path.join(dataset_path, labels)\n",
    "\n",
    "df = preprocess_df(df=pd.read_csv(labels_path), image_columns=image_col, images_path=images_path)\n",
    "\n",
    "model.get_embeddings(dataframe=df, batch_size=batch_size, image_col_name=image_col, text_col_name=text_col, output_dir=output_dir, output_file=output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddc1723",
   "metadata": {},
   "source": [
    "## 8. MIMIC CXR\n",
    "* **[MIMIC CXR](https://physionet.org/content/mimic-cxr/2.0.0/#files-panel)**:\n",
    "\n",
    "The MIMIC-CXR (Medical Information Mart for Intensive Care, Chest X-Ray) dataset is a large, publicly available collection of chest radiographs with associated radiology reports. It was developed by the MIT Lab for Computational Physiology and provides an extensive resource for training and evaluating machine learning models in the field of medical imaging, particularly in automated radiograph interpretation and natural language processing for clinical narratives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d142f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 24\n",
    "dataset = 'mimic'\n",
    "image_col = 'image_id'\n",
    "text_col = 'text'\n",
    "output_dir = f'Embeddings_vlm/{dataset}'\n",
    "output_file = 'embeddings_clip.csv'\n",
    "\n",
    "dataset_path = f'datasets/{dataset}/'\n",
    "images_dir = 'images/'\n",
    "labels = 'labels.csv'\n",
    "\n",
    "images_path = os.path.join(dataset_path, images_dir)\n",
    "labels_path = os.path.join(dataset_path, labels)\n",
    "\n",
    "df = preprocess_df(df=pd.read_csv(labels_path), image_columns=image_col, images_path=images_path)\n",
    "\n",
    "model.get_embeddings(dataframe=df, batch_size=batch_size, image_col_name=image_col, text_col_name=text_col, output_dir=output_dir, output_file=output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_fusion_v0_0_1]",
   "language": "python",
   "name": "conda-env-data_fusion_v0_0_1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
