{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5aa85e3b",
   "metadata": {},
   "source": [
    "### Modeling DAQUAR\n",
    "* [Dataset](https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/research/vision-and-language/visual-turing-challenge)\n",
    "\n",
    "* [Original Paper](chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://proceedings.neurips.cc/paper_files/paper/2014/file/d516b13671a4179d9b7b458a6ebdeb92-Paper.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd20088f",
   "metadata": {},
   "source": [
    "### Setup Environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b30b68c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from src.classifiers import process_labels, split_data\n",
    "from src.classifiers_base import preprocess_df\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "from src.multimodal_data_loader import VQADataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.classifiers_base import train_early_fusion, train_late_fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "decd4152",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'datasets/daquar/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f622ee91",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_path = os.path.join(PATH, 'labels.csv')\n",
    "images_path = os.path.join(PATH, 'images')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea28f6cd",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7b3a71e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>image_id</th>\n",
       "      <th>answer</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what is on the right side of the black telepho...</td>\n",
       "      <td>image3</td>\n",
       "      <td>desk</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what is in front of the white door on the left...</td>\n",
       "      <td>image3</td>\n",
       "      <td>telephone</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what is on the desk in the image3 ?</td>\n",
       "      <td>image3</td>\n",
       "      <td>book, scissor, papers, tape_dispenser</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what is the largest brown objects in this imag...</td>\n",
       "      <td>image3</td>\n",
       "      <td>carton</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what color is the chair in front of the white ...</td>\n",
       "      <td>image3</td>\n",
       "      <td>red</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12463</th>\n",
       "      <td>what is found below the chandelier in the imag...</td>\n",
       "      <td>image1448</td>\n",
       "      <td>table</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12464</th>\n",
       "      <td>what is on the floor in the image1449 ?</td>\n",
       "      <td>image1449</td>\n",
       "      <td>rug</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12465</th>\n",
       "      <td>what are around dining table in the image1449 ?</td>\n",
       "      <td>image1449</td>\n",
       "      <td>chair</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12466</th>\n",
       "      <td>what is at the opposite side of the dining tab...</td>\n",
       "      <td>image1449</td>\n",
       "      <td>decoration_item</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12467</th>\n",
       "      <td>what is behind the wall divider in the image14...</td>\n",
       "      <td>image1449</td>\n",
       "      <td>table</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12468 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question   image_id  \\\n",
       "0      what is on the right side of the black telepho...     image3   \n",
       "1      what is in front of the white door on the left...     image3   \n",
       "2                    what is on the desk in the image3 ?     image3   \n",
       "3      what is the largest brown objects in this imag...     image3   \n",
       "4      what color is the chair in front of the white ...     image3   \n",
       "...                                                  ...        ...   \n",
       "12463  what is found below the chandelier in the imag...  image1448   \n",
       "12464            what is on the floor in the image1449 ?  image1449   \n",
       "12465    what are around dining table in the image1449 ?  image1449   \n",
       "12466  what is at the opposite side of the dining tab...  image1449   \n",
       "12467  what is behind the wall divider in the image14...  image1449   \n",
       "\n",
       "                                      answer  split  \n",
       "0                                       desk  train  \n",
       "1                                  telephone  train  \n",
       "2      book, scissor, papers, tape_dispenser  train  \n",
       "3                                     carton  train  \n",
       "4                                        red  train  \n",
       "...                                      ...    ...  \n",
       "12463                                  table   test  \n",
       "12464                                    rug   test  \n",
       "12465                                  chair   test  \n",
       "12466                        decoration_item   test  \n",
       "12467                                  table   test  \n",
       "\n",
       "[12468 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(text_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed42a961",
   "metadata": {},
   "source": [
    "## Data Perparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f73685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features and labels vectors\n",
    "text_columns = 'question'\n",
    "image_columns = 'image_id'\n",
    "label_columns = 'answer'\n",
    "\n",
    "df = preprocess_df(df, image_columns, images_path)\n",
    "\n",
    "# Split the data\n",
    "train_df, test_df = split_data(df)\n",
    "\n",
    "# Process and one-hot encode labels for training set\n",
    "train_labels, mlb, train_columns = process_labels(train_df, col=label_columns)\n",
    "test_labels = process_labels(test_df, col=label_columns, train_columns=train_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ac0b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda2b611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d7c541",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = VQADataset(train_df, text_columns, image_columns, label_columns, mlb, train_columns, tokenizer)\n",
    "test_dataset = VQADataset(test_df, text_columns, image_columns, label_columns, mlb, train_columns, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80604e54",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd368ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = len(mlb.classes_)\n",
    "multilabel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cb78aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train early fusion model\n",
    "print(\"Training Early Fusion Model:\")\n",
    "train_early_fusion(train_loader, test_loader, output_size, num_epochs=30, multilabel=multilabel, report=True, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1320056d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train late fusion model\n",
    "print(\"Training Late Fusion Model:\")\n",
    "train_late_fusion(train_loader, test_loader, output_size, num_epochs=30, multilabel=multilabel, report=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64805635",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf82f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from src.classifiers_base import TextModel, VisionModel, EarlyFusionModel, LateFusionModel\n",
    "#text_model = TextModel()\n",
    "#image_model = VisionModel()\n",
    "#model = EarlyFusionModel(text_model=text_model, image_model=image_model, output_size=output_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:retina_embeddings_v0_0_1]",
   "language": "python",
   "name": "conda-env-retina_embeddings_v0_0_1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
