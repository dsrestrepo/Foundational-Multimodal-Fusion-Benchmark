{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "407f16d9",
   "metadata": {},
   "source": [
    "### Modeling DAQUAR\n",
    "* [Dataset](https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/research/vision-and-language/visual-turing-challenge)\n",
    "\n",
    "* [Original Paper](chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://proceedings.neurips.cc/paper_files/paper/2014/file/d516b13671a4179d9b7b458a6ebdeb92-Paper.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a8f7c4",
   "metadata": {},
   "source": [
    "### Setup Environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93a42ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from src.classifiers import process_labels, split_data\n",
    "from src.classifiers_base import preprocess_df\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "from src.multimodal_data_loader import VQADataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.classifiers_base import train_early_fusion, train_late_fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdf5c458",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'datasets/daquar/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5aa2e036",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_path = os.path.join(PATH, 'labels.csv')\n",
    "images_path = os.path.join(PATH, 'images')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db86a70",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e016f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>image_id</th>\n",
       "      <th>answer</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what is on the right side of the black telepho...</td>\n",
       "      <td>image3</td>\n",
       "      <td>desk</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what is in front of the white door on the left...</td>\n",
       "      <td>image3</td>\n",
       "      <td>telephone</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what is on the desk in the image3 ?</td>\n",
       "      <td>image3</td>\n",
       "      <td>book, scissor, papers, tape_dispenser</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what is the largest brown objects in this imag...</td>\n",
       "      <td>image3</td>\n",
       "      <td>carton</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what color is the chair in front of the white ...</td>\n",
       "      <td>image3</td>\n",
       "      <td>red</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12463</th>\n",
       "      <td>what is found below the chandelier in the imag...</td>\n",
       "      <td>image1448</td>\n",
       "      <td>table</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12464</th>\n",
       "      <td>what is on the floor in the image1449 ?</td>\n",
       "      <td>image1449</td>\n",
       "      <td>rug</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12465</th>\n",
       "      <td>what are around dining table in the image1449 ?</td>\n",
       "      <td>image1449</td>\n",
       "      <td>chair</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12466</th>\n",
       "      <td>what is at the opposite side of the dining tab...</td>\n",
       "      <td>image1449</td>\n",
       "      <td>decoration_item</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12467</th>\n",
       "      <td>what is behind the wall divider in the image14...</td>\n",
       "      <td>image1449</td>\n",
       "      <td>table</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12468 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question   image_id  \\\n",
       "0      what is on the right side of the black telepho...     image3   \n",
       "1      what is in front of the white door on the left...     image3   \n",
       "2                    what is on the desk in the image3 ?     image3   \n",
       "3      what is the largest brown objects in this imag...     image3   \n",
       "4      what color is the chair in front of the white ...     image3   \n",
       "...                                                  ...        ...   \n",
       "12463  what is found below the chandelier in the imag...  image1448   \n",
       "12464            what is on the floor in the image1449 ?  image1449   \n",
       "12465    what are around dining table in the image1449 ?  image1449   \n",
       "12466  what is at the opposite side of the dining tab...  image1449   \n",
       "12467  what is behind the wall divider in the image14...  image1449   \n",
       "\n",
       "                                      answer  split  \n",
       "0                                       desk  train  \n",
       "1                                  telephone  train  \n",
       "2      book, scissor, papers, tape_dispenser  train  \n",
       "3                                     carton  train  \n",
       "4                                        red  train  \n",
       "...                                      ...    ...  \n",
       "12463                                  table   test  \n",
       "12464                                    rug   test  \n",
       "12465                                  chair   test  \n",
       "12466                        decoration_item   test  \n",
       "12467                                  table   test  \n",
       "\n",
       "[12468 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(text_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce9f104",
   "metadata": {},
   "source": [
    "## Data Perparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba086943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (6795, 4)\n",
      "Test Shape: (5673, 4)\n"
     ]
    }
   ],
   "source": [
    "# Select features and labels vectors\n",
    "text_columns = 'question'\n",
    "image_columns = 'image_id'\n",
    "label_columns = 'answer'\n",
    "\n",
    "df = preprocess_df(df, image_columns, images_path)\n",
    "\n",
    "# Split the data\n",
    "train_df, test_df = split_data(df)\n",
    "\n",
    "# Process and one-hot encode labels for training set\n",
    "train_labels, mlb, train_columns = process_labels(train_df, col=label_columns)\n",
    "test_labels = process_labels(test_df, col=label_columns, train_columns=train_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e68e95e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>image_id</th>\n",
       "      <th>answer</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what is on the right side of the black telepho...</td>\n",
       "      <td>datasets/daquar/images/image3.png</td>\n",
       "      <td>desk</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what is in front of the white door on the left...</td>\n",
       "      <td>datasets/daquar/images/image3.png</td>\n",
       "      <td>telephone</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what is on the desk in the image3 ?</td>\n",
       "      <td>datasets/daquar/images/image3.png</td>\n",
       "      <td>book, scissor, papers, tape_dispenser</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what is the largest brown objects in this imag...</td>\n",
       "      <td>datasets/daquar/images/image3.png</td>\n",
       "      <td>carton</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what color is the chair in front of the white ...</td>\n",
       "      <td>datasets/daquar/images/image3.png</td>\n",
       "      <td>red</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6790</th>\n",
       "      <td>what are stuck on the wall in the image1440 ?</td>\n",
       "      <td>datasets/daquar/images/image1440.png</td>\n",
       "      <td>photo</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6791</th>\n",
       "      <td>what is in the top right corner in the image14...</td>\n",
       "      <td>datasets/daquar/images/image1440.png</td>\n",
       "      <td>window</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6792</th>\n",
       "      <td>what is in front of the window in the image1440 ?</td>\n",
       "      <td>datasets/daquar/images/image1440.png</td>\n",
       "      <td>cabinet</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6793</th>\n",
       "      <td>what are the things on the cabinet in the imag...</td>\n",
       "      <td>datasets/daquar/images/image1440.png</td>\n",
       "      <td>candelabra, book</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6794</th>\n",
       "      <td>what are around the dining table in the image1...</td>\n",
       "      <td>datasets/daquar/images/image1440.png</td>\n",
       "      <td>chair</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6795 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question  \\\n",
       "0     what is on the right side of the black telepho...   \n",
       "1     what is in front of the white door on the left...   \n",
       "2                   what is on the desk in the image3 ?   \n",
       "3     what is the largest brown objects in this imag...   \n",
       "4     what color is the chair in front of the white ...   \n",
       "...                                                 ...   \n",
       "6790      what are stuck on the wall in the image1440 ?   \n",
       "6791  what is in the top right corner in the image14...   \n",
       "6792  what is in front of the window in the image1440 ?   \n",
       "6793  what are the things on the cabinet in the imag...   \n",
       "6794  what are around the dining table in the image1...   \n",
       "\n",
       "                                  image_id  \\\n",
       "0        datasets/daquar/images/image3.png   \n",
       "1        datasets/daquar/images/image3.png   \n",
       "2        datasets/daquar/images/image3.png   \n",
       "3        datasets/daquar/images/image3.png   \n",
       "4        datasets/daquar/images/image3.png   \n",
       "...                                    ...   \n",
       "6790  datasets/daquar/images/image1440.png   \n",
       "6791  datasets/daquar/images/image1440.png   \n",
       "6792  datasets/daquar/images/image1440.png   \n",
       "6793  datasets/daquar/images/image1440.png   \n",
       "6794  datasets/daquar/images/image1440.png   \n",
       "\n",
       "                                     answer  split  \n",
       "0                                      desk  train  \n",
       "1                                 telephone  train  \n",
       "2     book, scissor, papers, tape_dispenser  train  \n",
       "3                                    carton  train  \n",
       "4                                       red  train  \n",
       "...                                     ...    ...  \n",
       "6790                                  photo  train  \n",
       "6791                                 window  train  \n",
       "6792                                cabinet  train  \n",
       "6793                       candelabra, book  train  \n",
       "6794                                  chair  train  \n",
       "\n",
       "[6795 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9699b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "046e14bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = VQADataset(train_df, text_columns, image_columns, label_columns, mlb, train_columns, tokenizer)\n",
    "test_dataset = VQADataset(test_df, text_columns, image_columns, label_columns, mlb, train_columns, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bd2d82",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bc8d39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input_size = len(text_columns)\n",
    "image_input_size = len(image_columns)\n",
    "output_size = len(mlb.classes_)\n",
    "multilabel = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72347ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Early Fusion Model:\n",
      "The number of parameters of the model are: 196081253\n",
      "Epoch 1/15 - Test Accuracy: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Train early fusion model\n",
    "print(\"Training Early Fusion Model:\")\n",
    "train_early_fusion(train_loader, test_loader, output_size, num_epochs=15, multilabel=multilabel, report=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cd8ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train late fusion model\n",
    "print(\"Training Late Fusion Model:\")\n",
    "train_late_fusion(train_loader, test_loader, output_size, num_epochs=15, multilabel=multilabel, report=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41ce806",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa21e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from src.classifiers_base import TextModel, VisionModel, EarlyFusionModel, LateFusionModel\n",
    "#text_model = TextModel()\n",
    "#image_model = VisionModel()\n",
    "#model = EarlyFusionModel(text_model=text_model, image_model=image_model, output_size=output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cf19b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:retina_embeddings_v0_0_1]",
   "language": "python",
   "name": "conda-env-retina_embeddings_v0_0_1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
