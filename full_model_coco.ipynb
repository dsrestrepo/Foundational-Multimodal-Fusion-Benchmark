{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e39c5a0",
   "metadata": {},
   "source": [
    "### Modeling DAQUAR\n",
    "* [Dataset](https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/research/vision-and-language/visual-turing-challenge)\n",
    "\n",
    "* [Original Paper](chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://proceedings.neurips.cc/paper_files/paper/2014/file/d516b13671a4179d9b7b458a6ebdeb92-Paper.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4e01fb",
   "metadata": {},
   "source": [
    "### Setup Environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b7a6f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from src.classifiers import process_labels, split_data\n",
    "from src.classifiers_base import preprocess_df\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "from src.multimodal_data_loader import VQADataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.classifiers_base import train_early_fusion, train_late_fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f66a4d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'datasets/coco-qa/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed26c258",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_path = os.path.join(PATH, 'labels.csv')\n",
    "images_path = os.path.join(PATH, 'images')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90db3950",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58f9b7e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>image_id</th>\n",
       "      <th>answers</th>\n",
       "      <th>types</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what is using umbrellas as a central theme</td>\n",
       "      <td>397899</td>\n",
       "      <td>sculpture</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what walks toward the rope perimeter fence</td>\n",
       "      <td>310683</td>\n",
       "      <td>elephant</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what is the color of the horses</td>\n",
       "      <td>23004</td>\n",
       "      <td>brown</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>where is the black cat laying down</td>\n",
       "      <td>117931</td>\n",
       "      <td>sink</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what is the color of the character</td>\n",
       "      <td>220218</td>\n",
       "      <td>purple</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117679</th>\n",
       "      <td>what are there grouped together here</td>\n",
       "      <td>406426</td>\n",
       "      <td>vegetables</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117680</th>\n",
       "      <td>what serves as the train trestle</td>\n",
       "      <td>545581</td>\n",
       "      <td>bridge</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117681</th>\n",
       "      <td>what is the color of the plate</td>\n",
       "      <td>40404</td>\n",
       "      <td>white</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117682</th>\n",
       "      <td>what is sleeping on the blue couch</td>\n",
       "      <td>570521</td>\n",
       "      <td>cat</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117683</th>\n",
       "      <td>how many people on a boat rowing in the water</td>\n",
       "      <td>139440</td>\n",
       "      <td>six</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117684 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            questions  image_id     answers  \\\n",
       "0          what is using umbrellas as a central theme    397899   sculpture   \n",
       "1          what walks toward the rope perimeter fence    310683    elephant   \n",
       "2                     what is the color of the horses     23004       brown   \n",
       "3                  where is the black cat laying down    117931        sink   \n",
       "4                  what is the color of the character    220218      purple   \n",
       "...                                               ...       ...         ...   \n",
       "117679           what are there grouped together here    406426  vegetables   \n",
       "117680               what serves as the train trestle    545581      bridge   \n",
       "117681                 what is the color of the plate     40404       white   \n",
       "117682             what is sleeping on the blue couch    570521         cat   \n",
       "117683  how many people on a boat rowing in the water    139440         six   \n",
       "\n",
       "        types  split  \n",
       "0           0  train  \n",
       "1           0  train  \n",
       "2           2  train  \n",
       "3           3  train  \n",
       "4           2  train  \n",
       "...       ...    ...  \n",
       "117679      0   test  \n",
       "117680      0   test  \n",
       "117681      2   test  \n",
       "117682      0   test  \n",
       "117683      1   test  \n",
       "\n",
       "[117684 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(text_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc824ac7",
   "metadata": {},
   "source": [
    "## Data Perparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23fa14c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117684/117684 [01:25<00:00, 1369.39it/s]\n",
      "100%|██████████| 117684/117684 [01:04<00:00, 1820.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (78736, 5)\n",
      "Test Shape: (38948, 5)\n"
     ]
    }
   ],
   "source": [
    "# Select features and labels vectors\n",
    "text_columns = 'questions'\n",
    "image_columns = 'image_id'\n",
    "label_columns = 'answers'\n",
    "\n",
    "df = preprocess_df(df, image_columns, images_path)\n",
    "\n",
    "# Split the data\n",
    "train_df, test_df = split_data(df)\n",
    "\n",
    "# Process and one-hot encode labels for training set\n",
    "train_labels, mlb, train_columns = process_labels(train_df, col=label_columns)\n",
    "test_labels = process_labels(test_df, col=label_columns, train_columns=train_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18229f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>image_id</th>\n",
       "      <th>answers</th>\n",
       "      <th>types</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what is using umbrellas as a central theme</td>\n",
       "      <td>datasets/coco-qa/images/000000397899.jpg</td>\n",
       "      <td>sculpture</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what walks toward the rope perimeter fence</td>\n",
       "      <td>datasets/coco-qa/images/000000310683.jpg</td>\n",
       "      <td>elephant</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what is the color of the horses</td>\n",
       "      <td>datasets/coco-qa/images/000000023004.jpg</td>\n",
       "      <td>brown</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>where is the black cat laying down</td>\n",
       "      <td>datasets/coco-qa/images/000000117931.jpg</td>\n",
       "      <td>sink</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what is the color of the character</td>\n",
       "      <td>datasets/coco-qa/images/000000220218.jpg</td>\n",
       "      <td>purple</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78731</th>\n",
       "      <td>where are diced meat and tomatoes mixed with c...</td>\n",
       "      <td>datasets/coco-qa/images/000000111606.jpg</td>\n",
       "      <td>bowl</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78732</th>\n",
       "      <td>what is parked at the airport and loading people</td>\n",
       "      <td>datasets/coco-qa/images/000000443687.jpg</td>\n",
       "      <td>airplane</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78733</th>\n",
       "      <td>what cut into two with soup</td>\n",
       "      <td>datasets/coco-qa/images/000000279104.jpg</td>\n",
       "      <td>sandwich</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78734</th>\n",
       "      <td>where is the white toilet sitting</td>\n",
       "      <td>datasets/coco-qa/images/000000534974.jpg</td>\n",
       "      <td>bathroom</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78735</th>\n",
       "      <td>what parked outside some stores on a roadside</td>\n",
       "      <td>datasets/coco-qa/images/000000443749.jpg</td>\n",
       "      <td>trucks</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78736 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               questions  \\\n",
       "0             what is using umbrellas as a central theme   \n",
       "1             what walks toward the rope perimeter fence   \n",
       "2                        what is the color of the horses   \n",
       "3                     where is the black cat laying down   \n",
       "4                     what is the color of the character   \n",
       "...                                                  ...   \n",
       "78731  where are diced meat and tomatoes mixed with c...   \n",
       "78732   what is parked at the airport and loading people   \n",
       "78733                        what cut into two with soup   \n",
       "78734                  where is the white toilet sitting   \n",
       "78735      what parked outside some stores on a roadside   \n",
       "\n",
       "                                       image_id    answers  types  split  \n",
       "0      datasets/coco-qa/images/000000397899.jpg  sculpture      0  train  \n",
       "1      datasets/coco-qa/images/000000310683.jpg   elephant      0  train  \n",
       "2      datasets/coco-qa/images/000000023004.jpg      brown      2  train  \n",
       "3      datasets/coco-qa/images/000000117931.jpg       sink      3  train  \n",
       "4      datasets/coco-qa/images/000000220218.jpg     purple      2  train  \n",
       "...                                         ...        ...    ...    ...  \n",
       "78731  datasets/coco-qa/images/000000111606.jpg       bowl      3  train  \n",
       "78732  datasets/coco-qa/images/000000443687.jpg   airplane      0  train  \n",
       "78733  datasets/coco-qa/images/000000279104.jpg   sandwich      0  train  \n",
       "78734  datasets/coco-qa/images/000000534974.jpg   bathroom      3  train  \n",
       "78735  datasets/coco-qa/images/000000443749.jpg     trucks      0  train  \n",
       "\n",
       "[78736 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5818f59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eceaf59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = VQADataset(train_df, text_columns, image_columns, label_columns, mlb, train_columns, tokenizer)\n",
    "test_dataset = VQADataset(test_df, text_columns, image_columns, label_columns, mlb, train_columns, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True, num_workers=8)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e44ad0",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e45f1136",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = len(mlb.classes_)\n",
    "multilabel = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057a5984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Early Fusion Model:\n",
      "The number of parameters of the model are: 252462\n",
      "Epoch 1/10 - Test Accuracy: 0.3997\n"
     ]
    }
   ],
   "source": [
    "# Train early fusion model\n",
    "print(\"Training Early Fusion Model:\")\n",
    "train_early_fusion(train_loader, test_loader, output_size, num_epochs=10, multilabel=multilabel, report=True, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78538f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train late fusion model\n",
    "print(\"Training Late Fusion Model:\")\n",
    "train_late_fusion(train_loader, test_loader, output_size, num_epochs=10, multilabel=multilabel, report=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821307e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a0e941",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from src.classifiers_base import TextModel, VisionModel, EarlyFusionModel, LateFusionModel\n",
    "#text_model = TextModel()\n",
    "#image_model = VisionModel()\n",
    "#model = EarlyFusionModel(text_model=text_model, image_model=image_model, output_size=output_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:retina_embeddings_v0_0_1]",
   "language": "python",
   "name": "conda-env-retina_embeddings_v0_0_1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
